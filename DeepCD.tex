%%
%% This is file `yanputhesis-sample.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% yanputhesis.dtx  (with options: `sample')
%% Copyright (C) 2022 by Shangkun Shen
%%
%% It may be distributed and/or modified under the conditions of the LaTeX
%% Project Public License, either version 1.3b of this license or (at your
%% option) any later version. The latest version of this license is in
%%     https://www.latex-project.org/lppl.txt
%% and version 1.3b or later is part of all distributions of LaTeX version
%% 2005/12/01 or later.
%%=============================================================================%
%% 设置论文格式（学位、盲评、Adobe 字体）
%%-----------------------------------------------------------------------------%
%% 博士、正常版本、不使用 Adobe 字体
%% \documentclass[lang=chs, degree=phd, blindreview=false, adobe=false]{yanputhesis}
%% 博士、盲评版本、不使用 Adobe 字体
%% \documentclass[lang=chs, degree=phd, blindreview=true, adobe=false]{yanputhesis}
%% 博士、正常版本、强制使用 Windows 系统字体
%%\documentclass[lang=chs, degree=phd, blindreview=false, winfonts=true]{yanputhesis}
%% 硕士、正常版本、不使用 Adobe 字体
\documentclass[lang=chs, degree=master, blindreview=false, adobe=false]{yanputhesis}
%% 硕士、盲评版本、不使用 Adobe 字体
%% \documentclass[lang=chs, degree=master, blindreview=true, adobe=false]{yanputhesis}
%%=============================================================================%
%% 导言区：请自行添加额外宏包
%%-----------------------------------------------------------------------------%
\usepackage{blindtext}                                      % 生成无意义文本
\usepackage{metalogo}                                       % 软件标志
\usepackage[binary-units=true]{siunitx}                     % 物理量单位
\usepackage{amsmath}                                        % 基础数学库
\usepackage{colortbl}
\usepackage[table]{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}  % 使用这个包来支持伪代码环境
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{ \textbf{Output:}} %UseOutput in the format of Algorithm
\definecolor{mycyan}{cmyk}{.3,0,0,0}

%%=============================================================================%
%% 参考文献（也可以是独立文件）
%%-----------------------------------------------------------------------------%
%%=============================================================================%
%% 基本信息录入
%%-----------------------------------------------------------------------------%
\title{半监督遥感影像 \\ 变化检测算法研究}{          % 中英文标题
   Research on semi-supervised \\ remote Sensing image change detection algorithm
}                                                           % 请自行断行
\author{\blindreview{温冬成}}{\blindreview{Dongcheng Wen}}  % 姓名（添加盲评标记）
\date{2025年4月}{April 2025}                                  % 答辩日期
\school{计算机学院}{School of Computer science}% 学院
\major{计算机技术}{Computer technology}                     % 专业 博士请添加 Ph
\advisor{\blindreview{冉令燕}}{\blindreview{Lingyan Ran}}      % 导师（添加盲评标记）
\studentnumber{2022262929}                                  % 学号

%%=============================================================================%
%% 文档开始
%%-----------------------------------------------------------------------------%
\begin{document}
%%-----------------------------------------------------------------------------%
%% 总前言，包含封皮页、中英文标题、中英文摘要、目录
%%-----------------------------------------------------------------------------%
\frontmatter                                                % 前言部分
\maketitle                                                  % 封皮页及标题页
%%-----------------------------------------------------------------------------%
\makeCommitteePage{                                         % 学位论文评阅人
    \reviewers{\fullBlindReview{5}}                         % 和答辩委员会名单
    \committee{2023 年 x 月 y 日}{
        \defenseChair{赵钱孙}{教授}{西北工业大学}
        \committeeMember{周吴郑}{教授}{西北工业大学}
        \committeeMember{冯陈褚}{教授}{西北工业大学}
        \committeeMember{蒋沈韩}{教授}{西北工业大学}
        \committeeMember{朱秦尤}{教授}{西北工业大学}
        \committeeMember{何吕施}{教授}{西北工业大学}
        \committeeMember{孔曹严}{教授}{西北工业大学}
        \defenseSecretary{金魏陶}{教授}{西北工业大学}
    }
}
%%-----------------------------------------------------------------------------%
\begin{abstract}                                            % 中文摘要开始
    遥感影像变化检测是遥感领域的重要研究课题，在许多军事领域以及民用应用中发挥着重要作用，例如，城市建设规划、森林环境保护、农村土地管理、自然灾害评估等民用领域和军事监视、导弹命中分析等军事领域。虽然基于深度学习的变化检测方法相比人工目视和传统机器学习方法已经在检测效率和准确性上取得了巨大的成功。但是其高度依赖于大量的标注训练数据，当有标注的训练样本减少时，模型的识别能力急剧下降。而且，变化检测任务的数据标注非常复杂，需要高精度几何图像配准和像素级精细标注，耗时耗力，而在如今非常成熟的对地观测技术之下，无标注的数据已经很容易获得，半监督学习可以有效利用这些大量的无标注样本进行训练。因此，本文着力研究里有限标注数据和大量无标注数据的情况下，从多个问题的角度设计半监督变化检测算法，以达到可观的性能。本文的主要研究内容如下：

    1）针对大量的无标注样本中不同样本个体之间存在很大的差异，模型为这些具有不同难易程度的样本生成的伪标签可靠性也不尽相同。本算法设计了一种自适应动态学习策略AdaSemiCD，旨在提高伪标签的准确性并简化训练过程。我们的框架结合了传统的半监督训练方法，并辅以两个创新的功能模块AdaFusion和AdaEMA。首先，我们利用AdaFusion在单个样本水平上对不确定性高的样本区域进行改造，从而提高伪标签的准确性。其次在AdaEMA模块中引入了模型级参数更新的自适应选择过程，使模型能够充分集成优越的参数。大量的实验结果表明了我们所提出的方法能够极大地改善伪标签的质量，使得变化检测性能更好。

    2）针对目前基于伪标签和一致性正则化的方法中，采用的固定阈值或者特定的阈值调整方案可能无法更有效地利用未标记的数据。本算法根据模型的学习状态自适应地调整置信度阈值，并进一步引入自适应类公平正则化惩罚机制，以克服变化检测任务中极度的类别不平衡问题，鼓励模型概率输出偏向于少类别。此外，我们还推导了一个截断的高斯函数来根据它们的置信度对样本进行损失加权，这可以看作是置信度阈值的软版本。大量的实验表明了自适应阈值的优越性，特别是在标记数据极其稀少的情况下。

    3）针对目前强弱增强一致性正则化方法中，在所有样本上都采用的固定增强方法和增强强度，从而导致某些样本得不到充分训练儿某些样本又会过度引入噪声的问题。本算法根据样本的难易程度，设计了一套自适应增强机制，包括自适应的增强算法选择，和自适应的增强强度选择，对每对无标注样本进行定制化的增强，达到样本多样性和低噪声的平衡，从而在同样的一致性约束下使得模型得到更好的训练。最后通过实验证明了这种自适应增强机制的有效性。
    \begin{keywords}                                        % 中文关键词开始
        变化检测 \sep 半监督 \sep 伪标签 \sep 自适应机制                       %
    \end{keywords}                                          % 中文关键词结束
\end{abstract}                                              % 中文摘要结束
%%-----------------------------------------------------------------------------%
\begin{engabstract}                                         % 英文摘要开始
    \noindent \blindtext                                    %
    \begin{engkeywords}                                     % 英文关键词开始
        thesis \ensep template \ensep \LaTeX                %
    \end{engkeywords}                                       % 英文关键词结束
\end{engabstract}                                           % 英文摘要结束
%%-----------------------------------------------------------------------------%
\tableofcontents                                            % 目录
\listoffigures                                              % 图目录（学校未做要求）
\listoftables                                               % 表目录（学校未做要求）
\printnomenclature                                          % 符号表（学校未做要求）
%%-----------------------------------------------------------------------------%
\mainmatter
\sDefault
\chapter{绪论}
\chaptermark{绪论}
\section{研究背景与意义}
随着科技水平的不断进步，人类的生产、生活对于自然界和人类世界都以更快的速度发挥着更重要的影响力，在以往可能经过数十年乃至几个世纪间的自然演变过程才造成的地球地形地貌变化，例如河流改道、填海填湖，在如今或许被缩短至数年甚至数月，观测和把握这种变化对我们分析和指导生产活动是一件非常重要的事情。目前相关的对地观测技术也得到了飞速的发展，人们借助于高空无人机和遥感卫星的对地传感器能够轻松完成对地球表面的信息采集，并实时返回遥感影像数据，这已经逐渐成为了人们了解和观测地球的主要方式。并且现代遥感成像技术的成熟也使得采集到的遥感图像具有较高的空间分辨率，从而为人们动态检测地表变化提供了可能性和便利性。

所谓的遥感影像变化检测（Remote sensing change detection, RSCD），本质上是一个二分类的问题，就是在卫星对于同一区域在不同时间拍摄的双时相图像对中，识别出感兴趣的目标变化区域，比如建筑物、水域、植被和道路。该技术在许多军事领域以及民用应用中发挥着重要作用，例如，城市建设规划、森林环境保护、农村土地管理、自然灾害评估等民用领域和军事监视、导弹命中分析等军事领域。在计算机技术的广泛应用之前，人类主要依靠人工目视法来进行这种变化检测并手动标注变化区域和类型，这种方法虽然可靠，但是依赖于专业研究人员的检测经验，并且在面对海量任务时，这种方法的可行性和经济性就受到了极大的挑战。伴随计算机科学的进步和机器学习的兴起，自动变化检测开始走入了人们的视线，早期广泛采用的基于传统机器学习算法的变化检测方法，其能够处理的遥感图像分辨率相对较低，主要包括:(1)基于图像差分、图像回归、图像比例、变化向量分析(CVA)等代数方法;(2)基于变换的方法，如主成分分析(PCA)、多元变化检测(MAD)、Gramm-Schmidt变化分析(GS)等，通过将高维特征投影到低维特征空间中，使特征分量去相关，从而突出重要的变化信息表示。(3)基于分类方法。例如，后分类比较方法。该方法首先对前后时间图像进行独立分类，然后逐像素比较两幅图像的分类结果，既可以回答“哪里发生了变化”的问题，也可以回答专家感兴趣的另一个问题“发生了什么变化”，但缺点也很明显，即高度依赖高精度高配准的分类结果，实施起来难度极大。

\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.55]{images/fig1.png}
	\caption{
		变化检测在各种领域的应用。
	}
	\label{fig:background}
\end{figure}

目前，深度学习算法已经被广泛应用到各种计算机视觉任务，比如图像分类、目标检测、深度估计，以及语义分割、实例分割等与变化检测相似的密集预测任务，并且表现出了远超传统方法的优异性能。然而，基于卷积神经网络（Convolutional Neural Network, CNN）或者Transformer网络的全监督的深度学习变化检测算法都及其依赖于大量的人工标注，当有标注的训练样本减少时，模型的识别能力急剧下降。而且，变化检测任务的数据标注非常复杂，需要高精度几何图像配准和像素级精细标注，耗时耗力。这一点从目前可以获取到的公开数据集的数据规模对比就可以看出来，通常图像分类、目标检测的数据集能够达到数十万张，而变化检测的数据集规模仅在几百至几万张。为了应对这些挑战，研究人员研究了一系列方法，如自监督学习（Self-supervised learning, SSL）、无监督变化检测（Unsupervised Change Detection, USCD）、弱监督变化检测（Weakly Supervised Change Detection, WSCD）和样本生成策略（sample generation strategies）。虽然弱监督变化检测具有一定的成本效益，但它依赖于不完整或不准确的标签，这可能会引入错误信号和不可预测的噪声数据。另一方面，无监督变化检测完全不使用标注数据，而是利用数据中存在的固有联系作为监督指导，这导致它在处理分类或检测等特定任务时，由于缺乏正确的语义信息而面临挑战。样本生成策略，包括数据增强[23]、生成式对抗网络和扩散模型，经常需要模拟或合成额外的数据样本。然而，当处理有限的可用样本时，由于生成的数据多样性不足，这些方法可能会遇到约束，从而降低模型的泛化能力。半监督变化检测有效弥补了这些方法的不足，一方面它能够从有限的标注数据中学习到正确的语义信息，另一方面还能够从大量的易获得的无标注数据分布中学习到更为多样的变化特征表示，因此，半监督变化检测成为了一种更有前景的解决方案。

在此背景之下，本文着力研究了半监督变化检测算法，针对模型为无标注样本生成的伪标签可能包含错误标签从而引入额外噪声这一问题，我们从提高无标注样本的伪标签的可靠性入手进行了一系列的研究，分别从无标注样本增强、模型参数更新、伪标签生成模型、伪标签生成策略等方面进行了改进，有效地提升了伪标签的质量，从而提高了半监督变化检测算法的性能。

\section{国内外研究现状及趋势}
此前国内外学者已经在半监督变化检测算法领域进行了大量的研究，本小节将介绍与本文最相关的几个方向的研究现状，包括半监督学习，全监督遥感影像变化检测，以及半监督遥感影像变化检测的基本任务与方法和研究发展历程。
\subsection{半监督学习算法}
在实际应用场景中，无标签的数据易于获取，而有标签的数据收集起来通常很困难，标注过程也是一项极度劳动密集的工作。在这种情况下，半监督学习（Semi-Supervised Learning, SSL）是一种克服样本标注困难问题的可行方法，近年来也已经成为深度学习领域一个热门的研究方向，其旨在仅利用一小部分标记数据进行监督训练，学习到正确的语音信息，同时利用大量的无标注训练样本进行无监督训练，以提高模型的泛化性，减少过拟合现象。SSL主要包含三种策略：一致正则化（Consistent Regularization, CR）、自训练（Self Training）、生成模型以及一些包括其中多种思想的整体方法。

一致性正则化方法基于扰动一致性的概念，所谓的扰动一致性即：如果对一个未标记的数据应用实际的扰动，则预测不应发生显著变化，因为在聚类假设下，具有不同标签的数据点在低密度区域是互相分离的。这种方法首先对输入数据施加不同程度的扰动，将模型在这些输入数据上的输出之间的一致性作为训练约束。目前的三个主流的一致性正则化训练框架包括：Π-模型[35]，时间集成模型[35]和平均教师（Mean-Teacher, MT）模型[32]。这几种框架都是以双分支网络作为基础架构，两个网络分支分别对扰动后的训练样本和原始训练样本进行前向推理，通过最小化两次推理的概率分布的均方误差（Mean Square Error, MSE）来优化模型参数。其中Π-模型的双分支网络之间是共享参数权重的，每次更新参数之后两个分支同步更新；时间集成模型合并时间序列上的所有输出结果，当前模型预测结果与历史预测结果的指数移动平均值（Exponential Moving Average, EMA）做均方误差计算，这有效地保留历史了信息，消除了扰动并稳定了当前值；MT模型从模型参数层面进行了平滑操作，学生模型的权重是历史模型参数的EMA集成，该模型在随后的各个领域的半监督研究中得到了应用，例如Active-Teacher用于半监督对象检测[36]，[33]，[37]-[39]用于半监督一般语义分割，[40]用于图像分类，[41][42]用于半监督医学图像分割。此外有研究人员也在扰动设计方面进行了探索，[43]和[25]分别在一致性正则化中应用了图像级扰动和特征级扰动。

基于自训练的半监督学习算法思想是：首先使用一个预测模型或它的某些变体来为无标注样本生成一些伪标签，将这些伪标签和有标注的数据样本混合在一起进行监督训练，提供一些额外的训练信息。一个最为关键的问题就在于伪标签的可靠性，因为这直接影响了模型的训练效果，因此大量的研究从此处入手，研究了生成高质量伪标签的方法。[44]采用一个设定的概率阈值作为选择标准，预测概率小于此阈值的类别标签直接被丢弃。ST++[45]开发了一种多层自训练结构，每个阶段选择一批高质量的伪标签参与到训练，反复进行此挑选和训练过程，直到所有未标记的样本都得到了利用。[46]计算出伪标签中每个像素的信息熵，使用一个恒定的熵值作为过滤阈值，排除那些不可靠的伪标签。此外还有一种协同训练（Co-training）框架\cite{co-training}，这种框架包含两个模型，分别为彼此提供伪标签。

基于生成模型的方法旨在利用生成模型对数据的分布进行建模，从而推断出未标注数据的潜在信息。半监督变分自编码器\cite{semiVAE}是变分自编码器（Variational Autoencoder, VAE）在半监督学习中的一种扩展方法，添加了一个分类器来学习语义信息，首先VAE从标注样本集中学习一个真实的数据分布，然后在大量的无标注样本上基于分类器分类结果去指导模型学习一个更为丰富的潜在分布。Ren等人[]利用生成对抗策略训练了一个能够生成共配准图像的生成器，从原始图像高维特征空间中采样，从特征空间分布的上界和下界之间按照策略选择一些特征向量生成高质量配准图像，从而后续只需用通过特征融合方法即可找出变化区域，并且扩充了学习到的特征空间。Bandara等人在大规模数据集上预训练了一个Denoising
Diffusion Probabilistic Models（DDPM），利用其具有强大表征能力的编码器进行双时图像的特征提取以提高变化检测性能。

通常情况下，实际应用中更多采用的是整体方法（Holistic Methods），即在一个框架中整合前述的 SSL 的主要方法，从而获得更好的性能。比如[33]、[38]-[40]和[45]这些研究工作。其中最为经典的是FixMatch\cite{sohn2020fixmatch}，提出了一种基于伪标签和一致性正则化的简单而有效的整体方法。进一步，Yang等人根据分类和分割任务的差异，增加了一种新的前馈流即特征摄动，以及一种极强的增强摄动流，通过多一致性约束构造更广阔的扰动空间。此外，他们同期关于半监督语义分割的另外两项研究考虑了在半监督语义分割训练中加入自适应调整机制，但他们的视野局限于训练数据，遗憾的是他们没有考虑更高层次的模型训练。

\subsection{基于深度学习的遥感影像变化检测}
受深度学习在各领域取得的巨大成功所启发，近十年在变化检测领域也涌现出了许多经典的工作，推动了遥感影像变化检测研究的发展，下面本小节将按照大致的时间顺序分别介绍基于CNN的变化检测方法、基于Transformer的变化检测方法以及近期出现的基于大模型的变化检测方法。
\subsubsection{基于CNN的变化检测方法}
CNN引入了卷积和池化网络层，使其能够有效地捕获数据中的空间特征和局部关系，同时通过深度网络结构层层提取更抽象的高维特征，经典的CNN架构包括LeNet-5、AlexNet、VGG、ResNet等。研究人员利用双分支孪生网络分别对两幅时相图像进行处理，提取高维特征，然后进行特征融合，识别出双时相图像对之间的差异。最为经典的工作是Daudt 等人\cite{daudt2018FC-EF}在2018年使用全卷积网络构建了基于UNet的架构及其两个孪生变体，这三种变化检测框架分别是FC-EF、FC-Siam-conc、FC-Siam-diff，每种框架都采用了不同的特征融合策略，其中FC-EF是在输入层面首先对双时相图像进行了图像级别的融合，另外两种都是对从双时相图像对中抽取的高维特征进行融合。Shi等人\cite{shi2021DSAMNet}提出的DSAMNet在每个多尺度特征融合阶段添加了卷积块注意模块（Convolutional Block Attention Modules，CBAM），这种轻量级的注意力机制从空间和通道两个维度上对特征之间的关系进行了建模，动态地调整了特征图地权重。Zhang等人\cite{zhang2023MFNet}提出了一个互特征学习网络——MFNet（Mutual Feature-Aware Networks），提出的对称变化特征融合模块弥补了此前差分特征融合造成的信息丢失问题，同时通过在编码阶段提前引入差异感知，使得编码器更加聚焦于对潜在变化区域的特征学习。Fang等人\cite{fang2021SNUNet}将孪生网络和稠密连接的NestedUNet网络结合到了一起，浅层特征和深层特征之间紧凑的信息传输减少了特征抽取中的位置信息丢失。Zheng等人提出的ChangeStar\cite{zheng2021changestar}通过构造伪配准图像对，以语义分割方式来处理两幅图像，以单时相图像来训练双时相图像对变化检测模型，减少了对特征融合和图像配准的依赖。总的来说，基于CNN的监督变化检测方法大多侧重于特征融合模块的设计或者精巧的编码器设计，以更加精确地表示变化特征。
\subsubsection{基于Transformer的变化检测方法}
Transformer 是一种基于自注意力机制的深度学习模型，最初由 Vaswani 等人在 2017 年提出\cite{vaswani2017transformer}，首次用于自然语言处理任务中的序列到序列（Seq2Seq）建模，尤其是在机器翻译任务中取得了革命性突破。其核心特性是完全抛弃了传统的循环神经网络（RNN）和卷积神经网络（CNN），以自注意力机制和全连接网络为基础，显著提高了模型在长程依赖任务中的效率和性能。随着Google Research 于 2020 年提出了Vision Transformer (ViT)\cite{dosovitskiy2020vit}，首次将Transformer网络应用到了计算机视觉领域，其迅速成为了计算机视觉领域的新宠方向，在变化检测领域亦是如此。Chen等人首先将VIT引入了变化检测任务，提出的BIT\cite{chen2021BIT} 是一种基于原生 Transformer 架构的网络，旨在通过Transformer对双时相图像的时空上下文进行建模。然而，该模型直接采用原生 Transformer 的解码器，未充分利用浅层特征，这限制了其性能。相比之下，Li 等人提出的TransUnet\cite{li2022transunetcd}引入了 UNet 风格的解码器，取代了 Transformer 原有的解码方式，通过融合上一阶段的特征图逐步恢复至原始尺寸，从而显著提升了模型的表现。NVIDIA 提出的 SegFormer \cite{xie2021segformer}是一种基于 Transformer 的通用语义分割架构，利用轻量级编码器实现多尺度特征提取。受其启发，Bandara 等人设计了 ChangeFormer\cite{bandara2022transformer}，该模型引入了针对变化检测任务的特定模块，通过卷积操作学习双时相特征图之间的变化关系。相比传统方法，ChangeFormer展现了更高的精度和鲁棒性。Jiang等人提出的VcT\cite{jiang2023vct}将每个像素作为一个图节点，利用图神经（GNN）网络对所有节点组成的结构化信息进行建模，挖掘具有共同背景信息的可靠token，而不是像以往手动设置固定token，更具针对性的特征学习提高了检测的效率和准确性。

一些研究发现，在变化检测中，由于数据有限，纯Transformer模型可能无法发挥其全部潜力。因此还有一些研究将CNN和Transformer结合在了一起，使得两种模型的优点能够互补，既可以利用CNN强大的局部信息捕捉能力，又能够利用Transformer兼顾对全局关系的建模，实现全局特征和局部特征学习的统一。比较经典的工作有Jiang提出的MSFCTNet\cite{jiang2024cnntranscd}和Li等提出的MCTNet\cite{lwm2023cnntransCD2}和ConvTransNet\cite{lwm2023cnntransCD}。这类方法总体思想基本一致，但这些研究人员分别从不同方向对CNN与Transformer的高效信息交互进行了改进和创新。
\subsubsection{基于大模型的变化检测方法}
近年来，大模型（Large Models）的发展成为人工智能领域的核心热点之一。这些模型以大规模参数、海量数据和复杂架构为特征，在自然语言处理、计算机视觉、强化学习等领域展现出卓越性能。它们通常基于自注意力机制（Self-Attention）驱动的Transformer模型，通过在大规模数据集上边的自监督预训练，获得了强大的通用表征提取能力，虽然这些模型和上一小节同属Transformer类型，但由于其带来的变革性突破，本小节将单独分析基于大模型的变化检测研究。自从自然语言处理领域的BERT、GPT问世并引起广泛关注以后，计算机视觉领域的预训练大模型也迅速地出现在了人们的眼前。其中SAM\cite{kirillov2023SAM}（Segment Anything Model）是图像分割通用大模型的开篇之作，以其强大的零样本推理能力和无需微调的交互式分割，被认为彻底颠覆了传统的深度学习方法。Li等人\cite{li2024LM}最早提出了结合大模型进行变化检测的新范式，提出了一个包含冻结基础模型（如CLIP\cite{radford2021clip}、SAM等）、双时态适配分支（Bi-TAB）以及它们之间的桥接模块三部分的双时态适配网络（BAN），将大模型的大量先验知识注入到了变化检测模型。Ding等人\cite{ding2024SAMCD}通过训练一个轻量级的适配器网络（Adapter）来更具针对性地利用SAM在遥感影像场景中强大的视觉表示能力对双时相图像进行特征提取。Liu等人\cite{liu2024changeagent}将大语言模型和变化检测模型结合起来，提出了一个变化检测智能体（Change-Agent），能够输入文本和图像两种模态的数据，按照输入指令交互式地检测感兴趣的变化区域。Dong等人\cite{dong2024changeclip}同样基于Clip进行了多模态变化检测的研究，他们将图像-文本编码的结果与解码阶段的视觉特征相结合，从而增强了图像的语义。Zheng等人\cite{zheng2024SAC}利用SAM强大的零样本扩展能力，基于构建的点提示以及SAM提取的特征空间在图像内和图像间的潜在相似性，进行无需训练的零样本推理，首次提出并应用到了零样本变化检测任务。但是这和传统意义上的零样本任务任然有差别，就是需要人工对每幅图像进行点提示的标注。
\subsection{半监督遥感影像变化检测}
对大量图像进行变化检测的精细标注非常耗时，目前解决此问题的方法主要集中在半监督变化检测上（Semi-supervised Change Detection，SSCD）。与第1.2.1小节的半监督算法研究类似，SSCD也主要分为两大类别，其一是基于一致性正则化的方法，其二是基于生成对抗模型（Generative Adversarial Network，GAN）的方法。

在一致性正则化方面，在变化检测中引入平均教师模型最早是由Bousias等人提出的[47]。然而，最初的实验结果并没有显示出相当大的潜力，因为与仅使用有限数量的标记数据进行完全监督学习的基准相比，这种SSCD方法存在不足。甚至随着真实标注数据越来越多，这种与全监督训练之间的性能差距仍在继续扩大。以此为基础，Mao等人[48]分别对教师模型和学生模型的输入进行了强、弱增强操作。此外，他们制定了一个额外的教师虚拟对抗训练组件，以进一步减少伪标签噪音的负面影响。此外，有的其他半监督方法使用单模型或具有共享权重的双分支模型。如Sun等[49]引入了孪生网络。他们结合了基于伪标签的额外自训练，采用阈值过滤来消除低质量的伪标签。这种过滤背后的基本原理在于低置信度的伪标签引入的潜在噪声，这可能对自训练产生不利影响。Hafner等人提出了一种双任务SSCD框架，该框架结合了建筑物分割和变化检测这两个密切相关的下游任务。他们在Siamese分割网络和变化检测网络产生的两个变化检测掩码之间设计了一种新的一致性约束。Bandara等[25]探索了新的正则化项，即基于特征的扰动，在特征层面应用各种数据扰动来扩展一致性约束的分布空间。该方法充分利用了未标记样本中嵌入的信息，在最近的工作中，Zhang等人[27]对未标记数据集施加了类一致性和特征一致性两个约束。通过将未标记样本在变化类和不变类上的特征表示对齐，模型可以从更接近真实分布的特征空间中学习，这使得他们极大地改进了SSCD的性能。

其他方法主要利用GAN这种生成模型，它最初是由Goodfellow在2014年提出的[51]。一些方法使用GAN来学习接近真实标记数据的特征分布空间[26]，[52]- [54]；另一部分使用GAN生成数据样本[55]，[56]；在最近的工作中，比较值得注意的研究是[18]提出了一种新的变化检测范式，将无监督、弱监督、区域监督和完全监督的变化检测统一到了一个端到端的框架中，在无监督变化检测中，主要目标被定义为最小化一个区域，使得生成网络可以在屏蔽该区域后产生与另一个时间的图像相似的图像。对于弱监督和新提出的区域监督变化检测任务，关键思想在于最小化一个区域，使判别网络在屏蔽该区域后无法区分真实不变图像对。虽然这些努力在SSCD中取得了巨大的成功，但GAN的高度不稳定训练使得超参数调整变得具有挑战性。此外，梯度消失的问题经常出现在训练阶段，以及如果没有实施额外的训练技术，鉴别器的强判别能力可能导致GAN的生成器和鉴别器之间的性能不平衡。因此，实现理想的最优场景是具有挑战性的，这使得该方法的基本应用有些复杂。

\section{本文主要内容及结构安排}
本文着力研究半监督变化检测任务，在少量有标注训练数据上学习正确的语义信息并在大量且易获得的无标注训练样本上学习到一个更加丰富的特征空间分布。其中一个关键问题就在于能否减少无标注样本训练中不可避免的噪声问题，这有两种解决方案：通过改善伪标签的质量来提高半监督变化检测的性能；从特征层面构造正则化项从而排除错误伪标签的重要影响。本文从这两点入手，主要研究内容如下：

1）基于伪标签评估的自适应半监督变化检测。针对大量的无标注样本中不同样本个体之间存在很大的差异，模型为这些具有不同难易程度的样本生成的伪标签可靠性也不尽相同。本算法设计了一种自适应动态学习策略AdaSemiCD，旨在提高伪标签的准确性并简化训练过程。我们的框架结合了传统的半监督训练方法，并辅以两个创新的功能模块AdaFusion和AdaEMA。首先，我们利用AdaFusion在单个样本水平上对不确定性高的样本区域进行改造，从而提高伪标签的准确性。其次在AdaEMA模块中引入了模型级参数更新的自适应选择过程，使模型能够充分集成优越的参数。大量的实验结果表明了我们所提出的方法能够极大地改善伪标签的质量，使得变化检测性能更好。

2）基于大模型先验的半监督变化检测。针对变化检测网络为无标注数据生成的伪标签质量不足可能引入大量额外噪声的问题，我们通过构建一个在包含遥感数据的大规模数据集上进行过预训练的大模型辅助模块，引入大量的先验知识；同时利用通用分割大模型在目标边界上的强大分割能力，通过几种不同的融合策略，从单时相分割掩码生成双时相变化检测掩码，以改善伪标签质量。实验表明从预训练通用分割大模型引入先验知识能够达到更好的变化检测性能。

3）基于特征对齐的半监督变化检测。

本文的章节结构安排如下：

第一章首先系统性地阐述了变化检测任务的应用场景和研究价值，以及半监督变化检测算法的研究背景和意义，然后梳理了目前国内外关于半监督学习、深度变化检测、半监督变化检测的研究进展和主流方法，最后介绍了本文的主要研究内容和文章结构安排。

第二章首先介绍了本文研究工作中用到的一些骨干特征提取网络和预训练大模型，之后对本研究工作中进行对比的几种经典半监督变化检测算法进行了阐述，最后详细介绍了本研究中采用的实验指标和用到的数据集。

第三章基于自适应动态阈值的半监督变化检测工作介绍。首先介绍了模型整体框架和设计的三种变化掩码生成策略，之后介绍了实验设置以及展示了取得的实验指标结果和可视化结果，通过大量的对比实验结果验证了本工作的有效性。

第四章基于伪标签评估的自适应半监督变化检测工作介绍。首先介绍了模型的整体框架以及训练流程，随后详细介绍了设计的伪标签评估指标，以及基于此指标设计的两个自适应模块。最后在实验部分报告了该研究方法在十个公开数据集上取得的实验结果，并与其他经典半监督变化检测算法在定性和定量上进行了公平的对比，最后通过消融实验证明了每个模块的有效性。

第五章基于特征对齐的半监督变化检测工作介绍。首先介绍了模型整体框架，以及我们对图像间的同类特征潜在相似性的探究，并随后介绍了以此为基础结合预训练大模型提出的多源特征对齐方法，最后通过大量的对比实验，验证了本章所提方法的优越性。

第六章总结与展望。从全局角度总结了本文的主要研究工作，并对未来半监督变化检测领域可以继续改进创新之处做出了展望。
\cleardoublepage
\chapter{相关技术}

本章将介绍本文基于深度学习的半监督变化检测算法研究中所用到的相关技术，为后续章节做好铺垫。具体包括：2.1小节中详细介绍本文几个研究工作中用到的深度神经网络，包括卷积神经网络，Vision Transformer以及Segment Anything Model的网络结构等；2.2小节对上一章节研究现状中概括性介绍的几个经典半监督变化检测算法进行了详细的阐述；2.3小节对本文所有实验所采用的实验指标进行了解释；2.4小节对本文所有进行实验的公开数据集进行了详细介绍。

\section{深度神经网络}
深度神经网络（Deep Neural Network, DNN）是一种以多层神经元结构为基础的机器学习模型，广泛应用于诸多领域，包括计算机视觉、自然语言处理、语音识别以及推荐系统等。基于任务需求，DNN衍生出多种具体架构，例如用于图像处理的卷积神经网络（Convolutional Neural Network, CNN），在序列建模中表现优异的循环神经网络（Recurrent Neural Network, RNN），以及基于多头自注意力机制对全局关系进行建模的Transformer架构。虽然神经网络并不是本文的主要研究方向，但是由于后续研究中会多次涉及卷积神经网络中比较经典的网络模型，因此在本小节将介绍后续研究工作所用到的几种骨干特征提取网络，即ResNet，Vision Transformer，以及基于Transformer预训练的通用分割大模型Segment Anything Model的模型结构。
\subsection{ResNet}
在深度学习的发展过程中，研究者们发现随着卷积神经网络层数的增加，模型的表达能力理论上会不断增强。然而，在实际训练深层网络时，却遇到了两个主要问题：（1）梯度消失和梯度爆炸问题；（2）退化问题。这些问题阻碍了深层神经网络的发展，最终何等人\cite{He2015ResNet}提出了残差网络（Residual Network, ResNet），通过在网络层之间引入残差连接使得前层的输出直接加到后层的输出上，如公式\ref{eq:resnet}所示，其中$x$代表输入特征，下标表示网络层序号，$W_l$代表第$l$层的参数，$F\left(x_l,W_l\right)$表示卷积映射。通过这种方式，梯度在反向传播时可以通过跳跃路径直接传播到前层，避免了梯度逐层递减的问题，从而缓解了梯度消失，同时即使一些层对学习贡献较小，残差连接可以保证网络的性能至少不会发生退化现象。
\begin{equation}
  \label{eq:resnet}
  x_{l+1} = x_l + F\left(x_l,W_l\right)
\end{equation}

此外残差结构还减少了优化深层网络的难度，是网络结构更加复杂、网络层数进一步增加成为了可能，从而显著提升了卷积神经网络的表征能力和性能，推动了深度学习向更深、更强的方向发展。比如何等人同时提出了具有不同网络层数的ResNet，包括ResNet-18、ResNet-34、ResNet-50、ResNet-101以及ResNet-152，它们的网络架构如图\ref{fig:resnet}所示。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.55]{images/resnet.png}
  \caption{
    不同深度的ResNet网络层次架构\cite{He2015ResNet}。
  }
  \label{fig:resnet}
\end{figure}
此外后续还有研究提出了一些ResNet变体，例如ResNetV2\cite{2019resnetV2}和ResNeXt\cite{xie2017ResNeXt}。根据网络深度和任务需求，ResNet中存在两种经典的残差块，一种是用于浅层网络（如ResNet-18和ResNet-34）的基本残差块（Basic Residual Block），包含两个$ 3\times3 $的卷积层和直接的跳跃连接，一种是用于深层网络（如ResNet-50、ResNet-101和ResNet-152）的瓶颈残差块（Bottleneck Residual Block），它将两个 $ 3\times3 $ 的卷积层替换为$1 \times 1$，$3 \times 3$，$1 \times 1$ 的卷积网络,其中前后两个$1 \times 1$卷积层分别用于降低和恢复特征通道数，有效地减少了计算量和参数量，网络结构如图\ref{fig:resblock}所示。本文研究工作中采用的是ResNet-50，一共包含4个卷积阶段，每一个阶段中分别有3，4，6，3个瓶颈残差块。


\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.55]{images/res-block.png}
  \caption{
    两种残差块的网络结构\cite{He2015ResNet}。
  }
  \label{fig:resblock}
\end{figure}

\subsection{Vision Transformer}
虽然CNN在计算机视觉任务（如图像分类、目标检测、语义分割等）中占据主导地位，然而其在捕捉长距离依赖和全局信息时存在很大局限性。与此同时，Transformer在自然语言处理（Natural Language Processing, NLP）领域取得了显著成功，尤其是在任务如机器翻译和文本生成中。Transformer的核心优势是通过自注意力机制（Self-Attention Mechanism）捕捉输入数据中全局依赖关系。受此启发，Dosovitskiy等人\cite{dosovitskiy2020vit}对Transformer进行改进使其能够适配计算机视觉任务，形成了Vision Transformer（ViT）架构。这种方法首次完全摆脱了卷积操作，在多个基准测试中展现出与甚至超越CNN的性能。它的核心思想是将图像分割为固定大小的图像块（patches），并将每个块视为一个独立的“词”，类似于NLP中的词嵌入，这些图像块嵌入向量通过Transformer的自注意力机制进行处理，从而实现对图像的全局理解。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.55]{images/ViT.png}
  \caption{
    Vision Transformer网络框架\cite{dosovitskiy2020vit}。
  }
  \label{fig:ViT}
\end{figure}

ViT的网络结构如图\ref{fig:ViT}所示，输入的图像首先被分割为大小为$P\times P$的非重叠图像块（patches），每个块展平为一维向量并通过线性映射嵌入到D维特征空间，假设图像大小为$H \times W$且通道数为$C$，则切割后共生成$N=\frac{H}{P} \times \frac{W}{P}$个图像块，这些块被视为Transformer的输入“词”。为保留块之间的空间顺序信息，ViT为每个嵌入向量添加一个可学习的位置编码，此外，在输入序列的起始位置插入一个特殊的分类标识符（[CLS] Token），该标识符的嵌入向量用于最终的分类输出，如公式\ref{eq:embeding}。经过嵌入和位置编码后的输入序列被送入由L层组成的Transformer编码器，每层包含多头自注意力机制（Multi-Head Self-Attention, MHSA）和前馈网络（Feed-Forward Network, FFN）。在MHSA中，每个图像块嵌入向量通过查询（Query）、键（Key）和值（Value）矩阵生成注意力权重，用以捕捉图像块间的全局关系，表示为公式\ref{eq:attention}。其中$Q$、$K$、$V$是从输入嵌入计算得到的查询、键和值矩阵，$\sqrt{d_{k}}$是注意力头的维度。每个Transformer层都配有残差连接和层归一化，用以提高训练稳定性。经过L层编码器后，分类标识符的嵌入向量$z_{0}^{[C L S]}$被用作图像的全局表示，并通过一个全连接层映射到类别数的维度，最终通过Softmax函数生成分类概率，如\autoref{eq:softmax}，其中$W_{\text {head }}$和$b_{\text {head }}$为分类头的参数。
\begin{equation}
  \label{eq:embeding}
  z_{0}=\left[z_{0}^{[C L S]} ; z_{0}^{1} ; z_{0}^{2} ; \ldots ; z_{0}^{N}\right]+E_{\mathrm{pos}}
\end{equation}
\begin{equation}
  \label{eq:attention}
\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{\top}}{\sqrt{d_{k}}}\right) V
\end{equation}
\begin{equation}
  \label{eq:softmax}
  \hat{y}=\operatorname{Softmax}\left(z_{L}^{[C L S]} W_{\text {head }}+b_{\text {head }}\right)
\end{equation}

ViT摒弃了传统卷积操作，采用自注意力机制实现图像全局特征的高效建模，其模块化和可扩展的架构使其在大规模数据集和高效计算资源支持下展现出优异性能。然而，ViT在小规模数据场景中仍面临一定挑战，主要体现在模型对训练数据的需求较高和计算效率的限制。因此，针对训练数据稀缺的情况，结合半监督学习算法是一种具有潜力的研究方向，通过充分利用未标注数据，有望显著提升ViT在小数据集场景下的表现。
\subsection{金字塔池化模型}
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.35]{images/PPM.png}
  \caption{
    金字塔池化模型架构\cite{zhao2017PPM}。
  }
  \label{fig:PPMfram}
\end{figure}
% \subsection{Segment Anything Model}
% 自然语言处理领域中基于Transformer的大模型（如GPT和BERT等）展现了跨任务和跨领域的通用性，这进一步推动了视觉领域对通用大模型的需求。受此启发，Meta AI提出了Segment Anything Model\cite{kirillov2023SAM}（SAM），旨在实现对任意图像或视频中的对象进行高效、精准的分割，而无需对具体类别或场景进行额外的训练。其设计理念与通用大模型相似，即通过大规模数据集预训练，使模型具有广泛的泛化能力，能够零样本或少样本适应新任务。其核心思想是通过一个提示驱动（prompt-driven）框架，允许用户通过灵活的提示方式（如点、框、文本描述等）来指定感兴趣的区域，从而实现高度交互性和可控性。SAM的提出不仅是计算机视觉技术发展的延续，更标志着分割任务从任务特定模型向通用模型转变的关键一步，开启了视觉任务中的“分割一切”。
% \begin{figure}[htb]
%   \centering
%   \includegraphics[scale=0.5]{images/SAM1.png}
%   \caption{
%     分割一切基础模型架构\cite{kirillov2023SAM}。
%   }
%   \label{fig:SAMfram}
% \end{figure}

% 为了实现这一目标，SAM引入了三个相互关联的组件来构建了分割的基础模型：一个基于提示的分割任务、一个通过数据标注提供动力并能够通过提示工程实现一系列任务零样本迁移的分割模型（SAM），以及一个用于收集数据集SA-1B的数据引擎，如图\ref{fig:SAMfram}。
% SAM的显著特性是支持多种类型的用户输入作为提示，包括：（1）单点提示，通过在目标对象上指定一个点，SAM能够快速分割该点所属的对象；（2）多点提示，当用户提供多个点时，模型能够根据点之间的关系生成更精确的分割；（3）框提示，通过提供一个边界框，模型可以分割框内的目标对象；（4）文本提示，与自然语言描述结合，通过文本指定需要分割的对象类别。这种灵活的提示驱动机制使SAM在复杂场景下能够通过用户少量交互即可实现高效分割。SAM的网络架构主要由三个主要部分组成，分别是图像编码器（Image Encoder），提示编码器（Prompt Encoder）以及掩码解码器（Mask Decoder）。其中图像编码器就是基于前文介绍的强大的ViT模型，用于提取高质量的全局图像特征，图像编码器在输入时对整幅图像进行一次性编码，生成具有全局上下文的多尺度特征嵌入。提示编码器用于编码用户提供的提示信息，包括点、框或文本等。点或框提示会被转换为位置嵌入，而文本提示则通过专门的文本编码器进行嵌入，提示编码器的设计使模型能够灵活适应多种提示形式。掩码解码器负责将图像编码器生成的全局特征与提示编码器的提示信息融合，生成与提示相关的分割掩码，如图\ref{fig:SAMfram}中所示的过程。此外SAM的强大性能得益于在一个规模空前的大型分割数据集上进行的预训练。该数据集包含超过11亿个图像-分割掩码对，覆盖了广泛的对象类别、场景和视觉条件。通过大规模预训练，SAM获得了卓越的通用性和泛化能力，能够分割未见过的对象或复杂场景中的目标，而无需进一步微调或额外标注。
% \begin{figure}[htb]
%   \centering
%   \includegraphics[scale=0.9]{images/SAM.png}
%   \caption{
%     Vision Transformer网络框架\cite{kirillov2023SAM}。
%   }
%   \label{fig:ViTfram}
% \end{figure}

% SAM是一项具有里程碑意义的技术，它通过灵活的提示驱动机制和大规模预训练，构建了一个适用于广泛视觉场景的分割模型。其强大的零样本推理能力和边界预测能力使得其可以不用微调直接用于其他场景和任务，并提供先验知识和辅助推理来优化性能，因此本文的研究工作中引入了SAM模型。
\section{经典半监督变化检测算法}
\subsection{SemiCDNet}
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.45]{images/SemiCDNetframe.png}
  \caption{
    SemiCDNet网络框架\cite{peng2021SemiCDNet}。
  }
  \label{fig:SemiCDNetfram}
\end{figure}
\subsection{RCR}
RCR（Revisiting Consistency Regularization）由Bandara等人\cite{bandara2022RCR}提出的，它们基于聚类假设构建了一个更加广阔的特征扰动空间，这种特征扰动一致性正则化使得模型具有更加强大的泛化能力。本文的研究工作的代码是基于RCR的变化检测网络和训练框架以及前文提到的平均教师模型改进实现的，因而有必要在本小节详细介绍RCR方法。

（1）网络框架。

总体框架如图\ref{fig:RCRfram}所示，主要包括三个模块：
1）编码器，用于提取前时相图像和后时相图像的隐藏特征表示。
2）特征差分模块，用于获取变化前和变化后图像的隐藏特征表示Fd的差异。
3）解码器，从隐藏的差异特征表示预测变化掩膜。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.45]{images/RCRframe.png}
  \caption{
    RCR网络框架\cite{bandara2022RCR}。
  }
  \label{fig:RCRfram}
\end{figure}

\textbf{编码器$f_{e}$}。对于编码器，RCR使用预训练的ResNet50\cite{He2015ResNet}。编码器的输出是2048维的特征矩阵，空间分辨率为$\frac{H}{4} \times \frac{W}{4}$，其中H和W分别为输入双时相图像$\left \{ I_A, I_B \right \} $的高度和宽度。在孪生网络架构中使用共享权重的双分支编码器，以分别提取两幅图像的隐藏特征表示$F_A$和$F_B$，数学公式表示为：
\begin{equation}
  \label{eq:RCRencode}
\begin{array}{l}
  F_{A}=f_{e}\left(I_{A}\right), \\
  F_{B}=f_{e}\left(I_{B}\right) .
  \end{array}
\end{equation}

\textbf{特征差分模块}。一旦从编码器获得给定双时相图像$\left \{ I_A, I_B \right \} $的隐藏特征表示$F_A$和$F_B$，RCR通过简单地计算$F_A$和$F_B$之间的绝对差值以获得隐藏特征的差分表示$F_d$，随后通过特征金字塔池化模块（Pyramid Pooling Module，PPM）\cite{zhao2017PPM} $f_{PPM}$对其进行处理，以有效地获取不同尺度的变化。用数学方法将特征差分模块内部的过程表示为：
\begin{equation}
  \label{eq:RCRppm}
  F_{d}=f_{\mathrm{PPM}}\left(\left|F_{A}-F_{B}\right|_{1}\right) .
\end{equation}

\textbf{编码器$f_{d}$}。解码器的目的是从隐藏的差分特征$F_d$中估计输出的变化概率图$\hat{y} $。j解码器中通过一系列亚像素卷积上采样模块\cite{shi2016upsample}，直到特征达到输入双时图像的空间分辨率$H \times w$。解码器内部的过程可以用数学表达为：
\begin{equation}
  \label{eq:RCRdecode}
  \hat{y}=f_{d}\left(F_{d}\right)
\end{equation}

（2）训练管道

训练以上变化检测的过程包含两个部分，一部分是在少量标注样本上进行的监督训练，另一部分则是在大量无标注样本上进行的无监督训练。

\textbf{监督训练}。
在这一阶段，RCR只预测标记训练数据所隐含的兴趣变化：$\mathcal{D}_{l}=\left\{\left\{I_{A, i}^{l}, I_{B, i}^{l}\right\}, y_{i}^{l}\right\}_{i=1}^{N_{l}}$, 其中$\left\{I_{A, i}^{l}, I_{B, i}^{l}\right\}$表示第$i$个双时相图像对，$y_{i}^{l}$是相应的真实变化掩码标注，${N_{l}}$是标记数据集的大小。利用预测值与真实标签之间计算的交叉熵（Cross Entropy， CE）损失\cite{murphy2012CE}作为监督损失$L_{sup}$，如公式\ref{eq:RCRLosssup}所示：
\begin{equation}
  \label{eq:RCRLosssup}
  \mathcal{L}_{\text {sup }}=\operatorname{CE}\left(\hat{y}_{i}^{l}, y_{i}^{l}\right)
\end{equation}

整个过程如图\ref{fig:RCRfram}-a所示。

\textbf{无监督训练}。
在这一阶段，除了标记数据$\mathcal{D}_{l}$，我们还使用未标记的双时相图像对$\mathcal{D}_{u}=\left\{I_{A, i}^{ul}, I_{B, i}^{ul}\right\}_{i=1}^{N_{ul}}$，其中$\left\{I_{A, i}^{ul}, I_{B, i}^{ul}\right\}$是第i个未标记的双时相图像对，$N_{ul}$是未标记数据集的大小，通常假设它大于标记数据集的大小（即$N_{u l} \gg N_{l}$）。为了有效地利用这些容易获得的未标记双时相图像来提高变化检测模型$f_{C D}(\cdot)$的性能，RCR提出了一个基于未标记数据的无监督损失$L_{unsup}$，它提供了一个额外的训练信号来优化$f_{C D}(\cdot)$的参数。所提出的无监督损失基于半监督学习中的聚类假设，其中RCR强制$f_{C D}(\cdot)$的预测在深度特征差分图$F_d$上施加不同随机扰动下依然保持一致，如图\ref{fig:RCRfram}-b所示。

定义$\left\{\left(\widetilde{F}_{d, i}^{u l}\right)_{1}, \cdots,\left(\widetilde{F}_{d, i}^{u l}\right)_{p}, \cdots,\left(\widetilde{F}_{d, i}^{u l}\right)_{p=N_{p}}\right\}$作为第i个未标记双时相图像对$\left\{I_{A, i}^{ul}, I_{B, i}^{ul}\right\}$的隐藏差分特征$F_{d, i}^{u l}$的随机扰动版本集合。接下来，RCR通过主解码器$f_d(\cdot)$对$F_{d, i}^{u l}$进行处理，得到预测的变化概率图为：
\begin{equation}
  \label{eq:RCRpredict}
  \hat{y}_{i}^{u l}=f_{d}\left(F_{d, i}^{u l}\right) .
\end{equation}

以及通过一组与$f_d(\cdot)$设计相似的辅助解码器处理隐藏特征差分图的每个扰动版本，得到它们对应的预测$\left(\widetilde{y}_{i}^{u l}\right)_{p}$为：
\begin{equation}
  \label{eq:RCRauxpredict}
  \left(\widetilde{y}_{i}^{u l}\right)_{p}=f_{d}^{p}\left(\left(\widetilde{F}_{d, i}^{u l}\right)_{p}\right), \text { where } p=1, \ldots, N_{p}
\end{equation}

接下来，RCR通过定义无监督损失$L_{unsup}$来强制$\left\{\left(\widetilde{y}_{i}^{u l}\right)_{p}\right\}_{p=1}^{N_{p}}$与$\hat{y}_{i}^{u l}$一致，如下公式所示：
\begin{equation}
  \label{eq:RCRLossu}
  \mathcal{L}_{\text {unsup }}=\sum_{p=1}^{N_{p}} \mathbf{d}\left(\left(\widetilde{y}_{i}^{u l}\right)_{p}, \hat{y}_{i}^{u l}\right),
\end{equation}

其中$d(\cdot)$是距离度量，用于测量预测之间的不相似性，在RCR中Bandara等人使用均方误差（Mean Squares Error，MSE）作为$d(\cdot)$。

（3）扰动方式

在RCR中，在输入特征上采取的扰动方式有以下几种：

1）随机特征噪声：随机生成一个三维噪声张量，然后根据$F_{d, i}^{u l}$中值的大小对其进行缩放，并将其添加到隐藏特征差分图中，得到一个扰动版本。

2）随机特性丢弃：首先通过阈值从特性差异图中选取出10$\%$到40$\%$的最需要的区域，生成掩膜，然后沿着通道维度，将潜在差分特征和该掩膜进行逐像素相乘，从而丢弃掉那些不需要的区域特征。

3）引导特征剪切：我们基于预测的变化图，从差分特征图中随机取零，得到扰动特征图。

4）内容和对象覆盖：基于变化检测网络的输出对变化类或不变类保持不变的假设，通过变化掩码掩盖隐藏差分特征图中的变化区域，或者通过不变掩膜掩盖隐藏差分特征图中的不变区域，创建隐藏差分特征图的两个扰动版本。

5）特征VAT\cite{2019VAT}：在变化最大的方向上对差分特征图应用对抗性扰动。
\subsection{FPA}
FPA（Feature-Prediction Alignment）是张等人\cite{Zhang2023FPA}2023年提出的半监督变化检测框架。FPA提出了两种对齐策略，来有效地利用未标记的双时相图像对进行训练。首先，设计了一种类感知特征对齐（Feature Alignment，FA）策略，将从不同未标记图像对（即跨区域）中提取的区域级变化/无变化特征进行对齐，以减少同一类内的特征差异。其次，设计了一种像素级预测对齐（Pixel- wise Prediction Alignment， PA）方法，将强增强未标记图像对的像素级变化预测与弱增强对应的伪标签进行对齐，以降低各种具有物理意义的图像对变换的预测不确定性。其总体框架如图\ref{fig:FPAfram}所示。其中使用的变化检测网络和监督训练过程都和RCR\cite{bandara2022RCR}相同，因此以下内容主要介绍其新颖的无监督训练部分。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.55]{images/FPAframe.png}
  \caption{
    FPA网络框架\cite{Zhang2023FPA}。
  }
  \label{fig:FPAfram}
\end{figure}

（1）类感知特征对齐

类感知特征对齐目的是在训练阶段实现小批量内不同未标记图像对的类内全局特征对齐。具体说来，首先对原始的无标记图像对施加弱增强操作，得到一个弱增强无标记图像对$\left\{\mathbf{x}_{a}^{u}, \mathbf{x}_{b}{ }^{u}\right\}$，并进一步继续对其施加强增强操作得到其对应的强增强图像对$\left\{\mathbf{x'}_{a}^{u}, \mathbf{x'}_{b}{ }^{u}\right\}$：
\begin{equation}
  \label{eq:FPAaug}
  \begin{aligned}
    \mathbf{x}_{a}^{\prime}{ }^{u} & =\operatorname{RandAugment}\left(\mathbf{x}_{a}{ }^{u}\right) \\
    \mathbf{x}_{b}^{\prime}{ }^{u} & =\operatorname{RandAugment}\left(\mathbf{x}_{b}{ }^{u}\right)
  \end{aligned}
\end{equation}

其中$RandAugment(\cdot)$表示从预定义的增强列表中随机抽样两个连接的强增强操作，增强列表如图\ref{fig:FPAstrongAug}所示，包括Identity，Contrast，Autocontrast，Brightness,，Color,，Equalize，Sharpness，Posterize和Solarize等9种常用增强方式，其中a-g分别是（a）原始图像；（b）Identity;（c）Contrast;（d）Autocontrast;（e）Brightness;（f）Color;（g）Equalize;（h）Sharpness;（i）Posterize;（j）Solarize。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.55]{images/Strong_aug.png}
  \caption{
    FPA使用的强增强操作列表\cite{Zhang2023FPA}。
  }
  \label{fig:FPAstrongAug}
\end{figure}

然后，通过编码器分别从$\left\{\mathbf{x}_{a}^{u}, \mathbf{x}_{b}^{u}\right\}$和$\left\{\mathbf{x'}_{a}^{u}, \mathbf{x'}_{b}{ }^{u}\right\}$中提取特征映射$f^u$和强增强特征映射$f'^u$。为了模型训练的鲁棒性，以解码器从$f^u$中提取的弱增强预测映射$p^u$作为伪标签参考，指导在强增强特征图$f'^u$上进行特征对齐操作。为了实现这一步，通过固定阈值筛选掉$p^u$中部分含噪较高的像素预测值：
\begin{equation}
  \label{eq:FPAthresh}
  \mathbf{m}^{u f}(i, j, k)=\left\{\begin{array}{ll}
    1, & \text { if } \quad \mathbf{p}^{u}(i, j, k)>\tau \\
    0, & \text { else }
    \end{array}\right.
\end{equation}

接下来对$m^{u f}$进行最近邻下采样为$\mathbf{m}^{u f} \in \mathbb{R}^{H / s \times W / s \times 2}$以适应强增强特征图$f'^u$的空间分辨率。如此一来便可以基于预测掩码$m^{u f}$和强增强特征映射$f'^u$，提取出分类全局特征向量，记为$\mathbf{v}^{\prime} \in \mathbb{R}^{2 \times C}$，以上过程用公司可表示为如下：
\begin{equation}
  \label{eq:FPAmetafeat}
  \mathbf{v}^{\prime}(k)=\frac{1}{\boldsymbol{w}(k)} * \sum_{i=1}^{H / s} \sum_{j=1}^{W / s} \mathbf{f}^{u}(i, j) * \mathbf{m}^{u f}(i, j, k)
\end{equation}

其中$*$表示逐像素点积运算，$\boldsymbol{w}(k)$为类权像素和，即变化类别的像素总数，计算过程如\ref{eq:FPAsum}，$\epsilon = 1e-8$是一个很小的余量，以避免每个类的权重可能为零。
\begin{equation}
  \label{eq:FPAsum}
\boldsymbol{w}(k)=\sum_{i=1}^{H / s} \sum_{j=1}^{W / s} \mathbf{m}^{u f}(i, j, k)+\epsilon
\end{equation}

最后为了实现跨区域的类内特征对齐，FPA通过增加它们的余弦相似度约束来使一个小批中的所有分类全局特征向量彼此对齐，无监督特征对齐损失计算如下：
\begin{equation}
  \label{eq:FPALossf}
  \begin{aligned}
    \mathcal{L}_{u}^{F A}= & \frac{1}{2 B B} \sum_{k=1}^{2} \sum_{i=1}^{B} \sum_{j=1}^{B} \mathbb{I}\left(\boldsymbol{w}_{i}(k)>0, \boldsymbol{w}_{j}(k)>0\right) \\
    & \cdot \frac{1}{2}\left(1-\frac{\mathbf{v}_{i}^{\prime}(k) * \mathbf{v}_{j}^{\prime}(k)}{\left\|\mathbf{v}_{i}^{\prime}(k)\right\|\left\|\mathbf{v}_{j}^{\prime}(k)\right\|+\epsilon}\right)
    \end{aligned}
\end{equation}

其中，$\mathbf{v}_{i}^{\prime}(k)$和$\mathbf{v}_{j}^{\prime}(k)$分别表示当前小批量（B为小批量大小）中第i和第j个未标记图像对的第k类全局特征向量。$\left(\mathbf{v}_{i}^{\prime}(k) * \mathbf{v}_{j}^{\prime}(k) /\left\|\mathbf{v}_{i}^{\prime}(k)\right\|\left\|\mathbf{v}_{j}^{\prime}(k)\right\|\right)）$表示$\mathbf{v}_{i}^{\prime}(k)$与$\mathbf{v}_{j}^{\prime}(k)$之间第k类全局特征的余弦相似度，其本身取值范围为[−1,1]，为了便于训练FPA将其重映射到了[0,1]。

（2）像素级预测对齐

像素级预测对齐的目的是使强增强图像对的输出与弱增强图像对的输出保持一致，从而使模型获得鲁棒的特征提取能力。为此，FPA中引入了\cite{sohn2020fixmatch}的置信度一致性学习策略，从半监督图像分类任务适用到SSCD的像素级任务。对于从弱增强图像对获取到的像素级的变化概率图$\mathbf{p}^{u}$，按以下方式生成伪标签映射$\hat{\mathbf{y}}^{u} \in \mathbb{R}^{H \times W}$：
\begin{equation}
  \label{eq:FPApesudo}
  \hat{\mathbf{y}}^{u}(i, j)=\underset{k=\{0,1\}}{\arg \max } \mathbf{p}^{u}(i, j, k)
\end{equation}

同样，为了减少噪声伪标签的干扰，对从$\mathbf{p}^{u}$生成的基于置信度的变化掩码$\mathbf{m}^{u p}\in \mathbb{R}^{H \times W}$基于一个固定阈值仅筛选出那些最为可信的预测像素。
\begin{equation}
  \label{eq:FPAfilter}
  \mathbf{m}^{u p}(i, j)=\left\{\begin{array}{ll}
    1, & \text { if } \quad \mathbf{p}^{u}\left(i, j, \hat{\mathbf{y}}^{u}(i, j)\right)>\tau \\
    0, & \text { else. }
    \end{array}\right.
\end{equation}

其中$\tau$是固定阈值的取值，在FPA中默认设置为0.95。

因此，第k个图像对的像素级预测对齐损失，可以表示为公式\ref{eq:FPALossp}和公式\ref{eq:FPALosspavg}：
\begin{equation}
  \label{eq:FPALossp}
  \mathcal{L}_{u}^{P A}(k)=\frac{1}{H W} \sum_{i=1}^{H} \sum_{j=1}^{W} \operatorname{CE}\left(\mathbf{p}^{\prime u}(i, j), \hat{\mathbf{y}}^{u}(i, j)\right) * \mathbf{m}^{u p}(i, j)
\end{equation}
\begin{equation}
  \label{eq:FPALosspavg}
  \mathcal{L}_{u}^{P A}=\frac{1}{B} \sum_{k=1}^{B} \mathcal{L}_{u}^{P A}(k) .
\end{equation}

最终整个无监督训练的损失函数即为类感知特征对齐损失和像素级预测对齐损失的求和：
\begin{equation}
  \label{eq:FPALossu}
  \mathcal{L}_{u}=\mathcal{L}_{u}^{F A}+\mathcal{L}_{u}^{P A} .
\end{equation}
\section{实验指标}
为了更好地衡量所有模型的性能，我们引入了2个广泛使用的变化检测评价指标，包括交并比（Intersection over Union，IoU）和总体精确度（Overall Accuracy，OA）。IoU、OA的取值范围均为0$\%$~100$\%$。对于所有这些指标，该值越大，变化检测性能就越好，但是在变化检测任务中，由于二分类和不平衡的类别不平衡，OA总体上都是一个很高的值。它们的计算表述如下：
\begin{equation}
  \label{eq:IoU}
  I o U=\frac{T P}{T P+F P+F N}
\end{equation}
\begin{equation}
  \label{eq:OA}
  O A=\frac{T P+T N}{T P+T N+F N+F P}
\end{equation}

其中$TP$和$TN$分别表示正确识别的变化像素数和未变化像素数。相反，$FP$表示未发生变化的像素被错误地分类为变化的像素的数量，$FN$表示发生变化的像素被错误地识别为未变化的像素的数量。此外，由于我们更关注变化区域的预测性能，并且变化类和背景类极度不平衡，因此在实验中使用变化类的$IoU$ （$IoU_c$）作为评价指标。
\section{实验数据集介绍}
本文中所有方法都在十个基准公开变化检测数据集上进行了实验，分别是LEVIR-CD\cite{chen2020levircd}、LEVIR-CD+\cite{chen2020levircd}、WHU-CD\cite{ji2018whu}、EGY-CD\cite{holail2023EGYCD}、HRCUS-CD\cite{zhang2023HRCUS}、Change Detection Dataset（CDD）\cite{Lebedev2018CDD}、GZ-CD\cite{peng2021SemiCDNet}、DSIFN-CD\cite{zhang2020dsifn}、SYSU-CD\cite{shi2022SYSU}和CL-CD\cite{liu2022CLCD}。其中，这些数据集涵盖了不同的分辨率（0.03m-2.0m）、不同的数据大小（2400至20000对）、不同的标注类别（二值建筑物或多类）、不同的图像对时间跨度（1年-16年），汇总如表\ref{datasets}所示，二值建筑物变化检测数据集部分样例展示如图\ref{fig:building_sample}所示，多类变化检测数据集部分样例展示如图\ref{fig:mutil_sample}所示。
\begin{table*}[!htbp]
  \centering
  \caption{本文所使用的公开数据集。}
  \begin{tabular}{c|c|c|c|c|c|c}
  \toprule[1pt]
  % \rowcolor[HTML]{DAE8FC}
  \rowcolor[HTML]{ECF4FF}
  \textbf{变化类别} &
    \textbf{数据集} &
    \textbf{空间分辨率} &
    \textbf{大小} &
    \textbf{样本数量} &
    \textbf{时间跨度} &
    \textbf{链接}
    \\
    % \hline
    \midrule
   & LEVIR-CD  \cite{chen2020levircd}  & 0.5m & 1024 $\times$ 1024   & 637 & 5到14年 &\href{https://justchenhao.github.io/LEVIR/}{\textcolor{blue}{Link}} \\
   \cline{2-7}
   & LEVIR-CD+ \cite{chen2020levircd}  & 0.5m & 1024 $\times$ 1024   & 985  & 5到14年
  &\href{https://justchenhao.github.io/LEVIR/}{\textcolor{blue}{Link}}\\
   \cline{2-7}
    &WHU-CD \cite{ji2018whu}&
    0.2m &
    15354$\times$32507 &
    1 &
    2012年至2016年
  &\href{http://study.rsgis.whu.edu.cn/pages/download/building_dataset.html}{\textcolor{blue}{Link}}\\
  \cline{2-7}
   & GZ-CD \cite{peng2021SemiCDNet}&
    0.55m &
    Varying &
    19 &
    2006年至2019年
  &\href{https://github.com/daifeng2016/Change-Detection-Dataset-for-High-Resolution-Satellite-Imagery}{\textcolor{blue}{Link}}\\
  \cline{2-7}
     & EGY-BCD \cite{holail2023EGYCD}&
    0.25m &
    256 $\times$ 256 &
    6091 &
    2015年至2022年
  &\href{https://github.com/oshholail/EGY-BCD}{\textcolor{blue}{Link}}\\
  \cline{2-7}
  \multirow{-5}{*}{\textbf{\begin{tabular}[c]{@{}c@{}} 建筑物\end{tabular}}} &
  HRCUS-CD \cite{zhang2023HRCUS}&
    0.5m &
    256 $\times$ 256 &
    11388 &
    混合
  &\href{https://github.com/zjd1836/AERNet}{\textcolor{blue}{Link}}\\
    \midrule
    % \hline
   & CDD\cite{Lebedev2018CDD}   & 0.03m-1.0m & 256$\times$256  & 16000    & 混合
   &\href{https://drive.google.com/uc?id=0B-IG2NONFdciOWY5QkQ3OUgwejQ&export=download}{\textcolor{blue}{Link}} \\
   \cline{2-7}
   & DSIFN-CD \cite{zhang2020dsifn} &Unknown & 512$\times$512   & 3940    & 未知
  &\href{https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images/tree/master/dataset}{\textcolor{blue}{Link}} \\
   \cline{2-7}
   & SYSU-CD\cite{shi2022SYSU} &0.5m & 256$\times$256 & 20000  & 2007年至2014年
   &\href{https://github.com/liumency/SYSU-CD}{\textcolor{blue}{Link}} \\
   \cline{2-7}
  \multirow{-4}{*}{\textbf{\begin{tabular}[c]{@{}c@{}} 多类\end{tabular}}}
   & CL-CD \cite{liu2022CLCD} &0.5-2.0m & 512$\times$512 & 600  & 2017年至2019年
   &\href{https://github.com/liumency/CropLand-CD}{\textcolor{blue}{Link}} \\
  \midrule
  \end{tabular}
  \label{datasets}
  \end{table*}

\textbf{LEVIR-CD数据集}：该数据集是一个综合性的遥感建筑变化检测数据集，由637对超高分辨率的谷歌地球图像块组成，每个块的空间分辨率为0.5m，尺寸为$1024\times1024$像素。这些双时相图像来自美国德克萨斯州七个城市的20个不同地点，双时相图像拍摄于2002年至2018年间，时间跨度在5到14年。经过切割之后，该数据集的分布是这样的：训练集占比为70$\%$（7120对），验证集占比为10$\%$（1024对），测试集占另外20$\%$（2048对）。

\textbf{LEVIR-CD+数据集}：LEVIR-CD+是对现有LEVIR-CD数据集的一个扩展版本，包含的样本数量扩充到985对$1024\times1024$像素的图像对，其中来自LEVIR-CD的637对用于训练，我们将其中的10$\%$用于验证，其余扩展的385对用于测试。

\textbf{WHU-CD数据集}：原始数据集由单个双时相图像对组成，其中包括2012年和2016年拍摄的新西兰克赖斯特彻奇的两张航拍图像。以同样的切割方式，我们将其分成7434个不重叠的图像对，每个图像对的大小为$256\times256$像素。训练、验证和测试数据集分别由5947、743和744对图像组成。

\textbf{GZ-CD数据集}：GZ-CD数据集的双时相图像收集于2006年至2019年，覆盖中国广州郊区。共收集了19幅不同尺寸的红、绿、蓝波段空间分辨率为0.55m的超分辨率图像，注释集中在建筑物变化上。经过切割成统一尺寸之后，共包含3603对样本，其中训练样本2882对，验证样本360对，测试样本361对。

\textbf{EGY-BCD数据集}：EGY-CD数据集包含6091张2015 - 2022年拍摄的$256 \times 256$像素的图像对，空间分辨率为0.25m/像素，主要标注了埃及4个城市和沿海地区的建筑变化区域。不用额外处理，我们将其中70$\%$用于训练，20$\%$用于验证，剩下的10$\%$用于测试。

\textbf{HRCUS-CD数据集}：该数据集由11388对高分辨率遥感图像组成，裁剪为$256 \times 256$像素，空间分辨率为0.5m。主要分为两个征集区，一个是城市建成区，时间跨度从2019年到2022年，建筑变化面积较少；另一个是正在建设的新城区，从2010年到2018年，包含农田、山地等多种地貌，建筑物变化面积较大。

\textbf{CDD数据集}：CDD数据集包含16000对$256\times256$像素的双时相图像对，像素分辨率从0.03到1米不等。所有这些双时间图像都是从谷歌地球收集的7对$4725\times2700$像素的季节性变化图像对中裁剪出来的。分别有10000对、3000对和3,000对用于训练、验证和测试。

\textbf{DSIFN-CD数据集}：DSIFN-CD是在谷歌地球上人工采集的，它由覆盖中国6个城市（北京、成都、深圳、重庆、武汉、西安）的6幅大型双时相超高分辨率图像组成。其中五个大图像对（北京、成都、深圳、重庆、武汉）被裁剪成394个子图像对，大小为$512\times512$像素。经过数据增强后，得到3940对双相图像。将西安图像对裁剪为48个子图像对进行测试。最终切割为统一的$256\times256$像素之后，训练数据集中有14400对图像，验证数据集中有1360对图像，测试数据集中有192对图像。

\textbf{SYSU-CD数据集}：该数据集由2007年至2014年在香港拍摄的20000对$256\times256$像素、 空间分辨率为0.5米航拍图像组成。数据集中的主要变化类型包括：(a)新建城市建筑；(b)郊区扩张；(c)施工前基础工作；(d)植被变化；(e)扩大道路；(f)近海建筑。我们将其中70$\%$的样本用于训练，20$\%$的样本用于验证，剩下的10$\%$的样本集用于测试。

\textbf{CL-CD数据集}：CL-CD数据集由600对农田变化样本图像组成，其中320对用于训练，120对用于验证，120对用于测试。CL-CD的双时相影像是2017年和2019年由中国广东省高分二号卫星采集的，空间分辨率范围为0.5-2 m。每组样本由两个$512 \times 512$像素图像和对应的字段变化的二进制标签组成。CL-CD中指出的主要变化类型包括建筑物、道路、湖泊和裸露的土地。我们将训练、验证、测试集都切割为$256\times256$大小之后进行使用。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.65]{images/building_sample.png}
  \caption{
    建筑物变化检测数据集部分样例图。
  }
  \label{fig:building_sample}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.65]{images/mutil_sample.png}
  \caption{
    多类变化检测数据集部分样例图。
  }
  \label{fig:mutil_sample}
\end{figure}

\section{本章小结}
本章主要介绍了本文研究内容的相关技术，首先简要介绍了卷积神经网络，主要包括本文中用到的ResNet模型。随后阐述了Vison Transformer模型的架构和原理。接着介绍了本文研究实验中使用的变化检测的 2 种最常用的评价指标。最后介绍了本文使用的十个公开数据集，所有实验均在这十个数据集上进行训练和验证。

\chapter{基于自适应动态阈值的半监督变化检测算法}
\section{引言}
半监督变化检测方法中基于伪标记和一致性正则化的方法带来了令人印象深刻的性能而取得了巨大的成功，其关键思想在于模型应该根据半监督学习中的平滑假设和低密度假设，在不同的扰动下对相同的未标记数据产生类似的预测或相同的伪标签。然而这种方法可能无法更有效地利用未标记的数据，因为它们要么使用预定义/固定的阈值，要么使用特设的阈值调整方案，仅使用通过阈值筛选出的可信未标记样本来进行训练。而没有特定于不同数据分布进行相应的针对性调整，导致性能较差，收敛速度较慢。

通常情况下，为保证伪标签的质量，需要设定一个高阈值。然而，固定的高阈值可能导致早期训练阶段的数据利用率低，并且忽略了不同类别的不同学习难度。Dash和admatch等半监督学习方法提出随着训练的进行，逐渐增加固定的全局（特定于数据集）阈值。虽然提高了对未标记数据的利用率，但这种特设阈值调整方案是由超参数进行控制，因此与模型的学习过程脱节。FlexMatch表明，不同的类应该有不同的局部（特定于类的）阈值。虽然局部阈值考虑了不同类别的学习差异，但它们仍然是从预定义的固定全局阈值映射出来的。Adsh通过优化每个类的伪标签数量，从预定义的非平衡半监督学习阈值中获得自适应阈值。总而言之，这些方法在根据模型的学习进度调整阈值方面均存在一些不足之处，从而阻碍了训练过程，特别是当标记数据过于稀缺而无法提供足够的监督时。

此外，此前的基于伪标签的半监督变化检测方法中，对于那些被筛选掉的低置信度预测都是直接丢弃，而这样可能造成的问题就是，训练后的模型可能会过度拟合到容易学习的样本上，而忽略了难学习的样本，从而产生“马太效应”，即本来就强的变得更强，本来就弱的变得更弱。

因此，我们认为需要根据模型的学习状态来自适应地确定阈值。具体来说，使用一个较低的全局阈值来利用更多的未标记数据，并在模型早期训练阶段加快收敛速度。随着训练过程的进行，预测置信度不断增加，此时使用更高的全局阈值来过滤掉错误的伪标签来减轻确认偏差。此外，由于变化检测中前景和背景类别的极度不平衡，还应该根据模型对变化和不变类预测的置信度，分别为前景、背景定义一个局部阈值，以减轻类别不平衡带来的预测偏向。并且我们增加了一个低置信度学习模块，旨在最大限度地利用整个未标记数据集，以提高训练过程中的泛化程度。具体来说，我们将来自低置信度预测的“软”伪标签中可能存在的正确信息通过一致性约束利用起来，以提高模型的性能和表征能力，最终提出了AdaThresh半监督变化检测框架。

本章介绍了基于自适应动态阈值的半监督变化检测算法，首先整体性的阐述了算法的框架和训练流程，随后详细介绍了基于预测概率分布的全局动态阈值和类别动态阈值，以及设计的低置信度学习模块。最后在实验部分报告了本章方法在十个公开数据集上取得的实验结果，从定性和定量两个角度进行了全方位的对比，以及全面的消融实验分析，验证了AdaThresh的有效性。
\section{基于自适应动态阈值的半监督变化检测框架}
\subsection{整体框架}
如图\ref{fig:AdaTh_frame}展示了AdaThresh的整体框架，AdaThresh采用了经典的教师学生模型（Mean-Teacher）作为主架构。其中学生模型为最终的训练目标模型，教师模型作为辅助模型，用于未标记数据的伪标签生成。

\textbf{问题定义}：
给定一个标记数据集$D_{l}=\left\{\left\{x_{a, i}^{l}, x_{b, i}^{l}\right\}, y_{i}^{l}\right\}_{i=1}^{m}$,一个无标注数据集$D_{u}=\left\{x_{a, j}^{u}, x_{b, j}^{u}\right\}_{j=1}^{n}$，其中$\left\{\left\{x_{a, i}^{l}, x_{b, i}^{l}\right\}, y_{i}^{l}\right\}$代表第i个双时相图像对和真实标签，以及$\left\{x_{a, j}^{u}, x_{b, j}^{u}\right\}$代表第i对未标记图像对，下标a和b分别是用于标识双时相图像对的前、后时相的图像，标注数据集和无标注数据集的样本数量分别是n和m, 并且$n \gg m$，模型M不仅在$D_{l}$上进行监督学习，还在$D_{l}$上进行无监督学习。

监督学习过程即通过最小化学生模型预测概率与真实样本标签之间的交叉熵损失来优化模型的参数；无监督学习过程通常情况下将教师模型的输出作为训练指导，对于教师模型在无标记样本上的输出概率，通过一个阈值来筛选出可信的预测作为伪标签，然后最小化学生模型输出概率和伪标签之间的交叉熵损失来优化学生模型的参数。教师模型的参数更新则由学生模型参数的移动指数平均累计得到。此外通常情况下，在此框架中还引入了一致性正则化，即对无标记样本分别进行弱增强以及在此之上的进一步的强增强，分别作为教师模型和学生模型的输入，基于低密度假设和平滑假设，二者的输出结果应该保持一致。通过一致性正则化，能够进一步提高模型的泛化能力。

很明显，生成伪标签过程中的阈值筛选是一个非常重要的过程，阈值过高会导致对无标记数据的利用率不足，而阈值过低又会导致引入错误标签。并且对于不同数据分布，最佳阈值的选择往往不相同，需要通过实验来验证。因此，我们设计了一种自适应的动态阈值调整机制，根据模型在不同数据上的预测概率分布，动态更新模型对于前景和背景的概率筛选阈值。此外，还设计了一个额外的低置信度学习模块，进一步提高对无标记数据的利用率。我们将在下面的小节中分别对这些设计进行详细阐述。
\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.35]{images/AdaThFrame.png}
	\caption{
		AdaThresh算法的整体框架。
	}
	\label{fig:AdaTh_frame}
\end{figure}
\subsection{全局自适应阈值}
在我们的自适应阈值机制中，首先估计一个全局阈值作为模型置信度的均线。当训练开始时，阈值较低，此时接受更多可能正确的样本进入训练以加快模型的收敛速度。随着模型预测变得更加自信，全局阈值自适应地增加，以过滤掉可能不正确的样本，减少确认偏差。
\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.35]{images/adath_plot.png}
	\caption{
		训练过程中的全局自适应阈值。
	}
	\label{fig:AdaTh_frame}
\end{figure}
具体说来，我们基于以下两个原则设计全局阈值。首先，全局阈值应该与模型对未标记数据预测的概率分布相关，要尽可能地反映模型的整体学习状况。此外，全局阈值应该在训练过程中稳定地增加，以确保丢弃错误的伪标签。考虑到以上两点，我们将全局阈值$\tau_t$设置为模型对未标记数据的平均置信度，其中$t$表示第$t$个迭代轮次。为了使得阈值保持平滑，我们将全局置信度估计为每个训练时间步的置信度的指数移动平均（EMA），并且在训练初始时间将全局阈值设置为每种类别的平均预测概率，即0.5。综上，全局动态阈值的计算公式如\ref{eq:Adath_global}所示：
\begin{equation}
    \label{eq:Adath_global}
    \tau_{t}=\left\{\begin{array}{ll}
      0.5, & \text { if } t=0 \\
      \lambda \tau_{t-1}+(1-\lambda) \frac{1}{\mu B} \sum_{b=1}^{\mu B} \max \left(p_{w, j}^{u}\right), & \text { otherwise }
      \end{array}\right.
\end{equation}

其中，$p_{w, j}^{u}$为教师模型在弱增强输入图像上的预测概率输出，$\lambda$为EMA的衰减动量，通常为一个接近1.0的超参数。
\subsection{类别自适应阈值}
类别动态阈值旨在以特定于前景变化类别和背景不变类的方式调节各自的阈值，以考虑类内多样性和两种类别的差异性。我们分别计算模型对两种类别的预测概率分布的期望，以此来估计模型特定于类别的学习状态，具体地说，就是基于模型特定于类别的平均置信度，动态调整全局置信度在每个类别上的表示。同样地，我们也是将类别平均置信度估计为在每个训练时间步的置信度的指数移动平均（EMA），并且在训练初始时间将类别置信度设置为一个均匀分布，即（0.5，0.5）。计算公式如下:
\begin{equation}
    \label{eq:Adath_pmodel}
    \tilde{p}_{t}(c)=\left\{\begin{array}{ll}
      0.5, & \text { if } t=0 \\
      \lambda \tilde{p}_{t-1}(c)+(1-\lambda) \frac{1}{\mu B} \sum_{b=1}^{\mu B} p_{w, j}^{u}(c), & \text { otherwise }
      \end{array}\right.
\end{equation}

其中$\tilde{p}_{t} = [\tilde{p}_{t}[0], \tilde{p}_{t}[1]]$是包含前景和背景类别的预测概率分布的期望。然后对其进行一个最大归一化，将归一化后的值作为类别阈值权重，最终特定于类别的自适应动态阈值结合了全局动态阈值和类别置信度期望，公式表示为：
\begin{equation}
  \label{eq:Adath_weight}
  \mathcal{W}(c)=\frac{\tilde{p}_{t}(c)}{\max \left\{\tilde{p}_{t}(c): c \in[0, 1]\right\}}
\end{equation}
\begin{equation}
  \label{eq:Adath_localTh}
  \tau_{t}(c)=\mathcal{W}(c) \times \tau_{t}
\end{equation}

则基于伪标签学习的训练损失为：
\begin{equation}
  \label{eq:Adath_argmax}
  \hat{y}_{i}^{u}=\max \left(p_{s, j}^{u}\right)>\tau_{t}\left(\arg \max \left(p_{w, j}^{u}\right)\right.
\end{equation}
\begin{equation}
  \label{eq:Adath_lossU}
  \mathcal{L}_{u}=\frac{1}{\left|\mathcal{B}_{u}\right|} \sum_{j=1}^{\left|\mathcal{B}_{u}\right|} \operatorname{CE}\left(p_{s, j}^{u}, \hat{y}_{i}^{u}\right)
\end{equation}

其中，$p_{s, j}^{u}$为学生模型在强增强输入图像上的预测概率输出。
\subsection{低置信度学习}
在上一步的筛选过程中，剔除掉了许多低置信度的标签，仅使用高置信度的预测作为硬伪标签。这一做法基于这样一种假设：高置信度的标签都是正确的，而低置信度的标签都是错误的。但是我们在研究中发现，被筛选掉的一部分低置信度标签中也包含着正确的标签信息，但是在模型学习过程中没有得到充分的利用。因此我们将这部分低置信的标签并不完全丢弃，而是将其作为软伪标签，利用强弱增强图像对之间的输出一致性正则化对其进行学习。具体地，我们使用KL散度作为低置信度学习的损失函数，计算公式如下：
\begin{equation}
  \label{eq:Adath_lossSoft}
  \mathcal{L}_{\mathrm{KL}}=\frac{1}{\mu B} \sum_{b=1}^{\mu B} \left(\max \left(p_{w, j}^{u}\right)<\tau_{t}\left(\arg \max \left(p_{w, j}^{u}\right)\right)\right) D_{\mathrm{KL}}\left(p_{s, j}^{u}, p_{w, j}^{u}\right)
\end{equation}

综上，我们的AdaThresh的总体损失表示为：
\begin{equation}
  \label{eq:Adath_lossSoft}
  \mathcal{L}_{total}=\mathcal{L}_{s}+\lambda_{u} \mathcal{L}_{u}+\lambda_{k} \mathcal{L}_{KL}
\end{equation}

$\lambda_{u}$和$\lambda_{k}$分别是硬标签交叉熵损失和软标签KL散度损失的权重超参数，我们会在消融实验部分对其取值选择进行探究。

\section{实验结果及分析}
\textbf{数据划分}：我们对所有数据集遵循相同的标记比例划分设置，我们选择5$\%$，10$\%$，20$\%$和40$\%$作为标记样本的比例，此比例表示我们将整个训练集的这部分样本视作有标记训练样本，其余样本我们仅使用训练图像对而不使用相应的真实标签，即视作无标记样本。其中在LEVIR-CD和WHU-CD上我们遵循\cite{bandara2022RCR}\cite{Zhang2023FPA}中的半监督划分，并对其他数据集执行我们自己的随机划分，但我们对于所有对比实验都是使用此相同的训练样本集进行公平的实验对比。

\textbf{实现细节}：为了防止网络结构带来的性能差异影响我们的结论，我们所有对比方法均使用ResNet50+PPM（Pyramid pooling module，特征金字塔池化模型）作为我们的变化检测网络。我们将初始学习率设置为0.01，它以0.9的动量随训练进程逐渐线性降低到1e-4，并使用SGD优化器训练所有方法。所有的模型都进行了80个epoch的训练，每个批次的标记和未标记mini-batch大小均设置为8。此外，所采用的所有数据增强方式都与\cite{Zhang2023FPA}中使用的增强方式相同，其中弱增强包括随机翻转、随机缩放、随机裁剪，强增强包括\cite{cubuk2020randaugment}中引用的9种强增强方式。由于标记数据的数量有限，模型对伪标签的过滤阈值非常敏感，在之前的研究中\cite{Zhang2023FPA}已经对阈值大小进行了消融研究，因此我们在对10个数据集进行的实验中将所有模型的阈值$\tau$按照经验都设置为0.95，并根据\cite{bandara2022RCR}$\phi$设置为5。我们所有的实验均利用PyTorch框架实现并且在4块NVIDIA GeForce RTX 3090 gpu上进行模型训练。
\subsection{对比试验}
\begin{table}[!htbp]
  \centering
  % \tiny
  \scriptsize
  \caption{不同CD方法在二值建筑物变化检测数据集上的平均定量性能对比。}
  \resizebox{0.8\textwidth}{!}{
  \begin{tabular}{p{20mm}p{20mm}p{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}} %
      \toprule
      \multirow{2}{*}{Dataset} & \multirow{2}{*}{\parbox[c]{.2\linewidth}{Method}} & \multicolumn{2}{c}{5\%} & & \multicolumn{2}{c}{10\%} & & \multicolumn{2}{c}{20\%} & & \multicolumn{2}{c}{40\%}\\
      \cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10} \cmidrule{12-13}
      & & {$IoU^c$} & {OA} && {$IoU^c$} & {OA} & & {$IoU^c$} & {OA} &&{$IoU^c$} & {OA}\\
      \midrule
      \multirow{8}{*}{LEVIR-CD}
      & Sup. only   &   61.0 & 97.60 && 66.8 & 98.13 && 72.3 & 98.44 && 74.9 & 98.60 \\ %40
      & AdvEnt\cite{vu2019advent}& 66.1 & 98.08 && 72.3 & 98.45 && 74.6 & 98.58 && 75.0 & 98.60 \\ %40
      & s4GAN\cite{mittal2019semi}& 64.0 & 97.89 && 67.0 & 98.11 && 73.4 & 98.51 && 75.4 & 98.62 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 67.6 & 98.17 && 71.5 & 98.42 && 74.3 & 98.58 && 75.5 & 98.63 \\ %40
      & RCR\cite{bandara2022RCR}& 72.5 & 98.47 && 75.5 & 98.63 && 76.2 & 98.68 && 77.2 & 98.72 \\
      & FPA\cite{Zhang2023FPA}& \underline{73.7} & \underline{98.57} && \underline{76.6} & \underline{98.72} && \underline{77.4} & \underline{98.75} && \underline{77.0} & \underline{98.74} \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{77.7} & \textbf{98.78} && \textbf{79.4} & \textbf{98.87} && \textbf{80.3} & \textbf{98.92} && \textbf{80.6} & \textbf{98.93} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 77.9} and OA=\textcolor{red}{\bf 98.77}} \\
      \bottomrule
      %\midrule
      \multirow{8}{*}{LEVIR-CD+}
      & Sup. only   &   52.0 & 97.72 && 58.4 & 98.06 && 66.1 & 98.31 && 66.2 & 98.42 \\ %40
      & AdvEnt\cite{vu2019advent}& 52.2 & 97.68 && 59.9 & 98.11 && 65.9 & 98.37 && 68.0 & 98.51 \\ %40
      & s4GAN\cite{mittal2019semi}& 46.5 & 97.25 && 51.4 & 97.66 && 62.8 & 98.18 && 67.2 & 98.46 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 52.6 & 97.66 && 60.7 & 98.24 && 64.8 & 98.37 && 66.1 & 98.38 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{64.9} & 98.25 && \underline{67.5} & \underline{98.45} && 68.5 & 98.52 && 68.4 & 98.51 \\
      & FPA\cite{Zhang2023FPA}& 64.6 & \underline{98.30} && 67.3 & 98.40 && \underline{70.3} & \cellcolor{mycyan}\textbf{98.64} && \underline{69.0} & \underline{98.59} \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{66.7} & \textbf{98.49} && \textbf{68.8} & \textbf{98.51} && \textbf{70.6} & \cellcolor{white}\underline{98.63} && \textbf{70.9} & \textbf{98.64} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 70.5} and OA=\textcolor{red}{\bf 98.63}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{WHU-CD}
      & Sup. only   &   50.0 & 97.48 && 55.7 & 97.53 && 65.4 & 98.20 && 76.1 & 98.94 \\ %40
      & AdvEnt\cite{vu2019advent}& 55.1 & 97.90 && 61.6 & 98.11 && 73.8 & 98.80 && 76.6 & 98.94 \\ %40
      & s4GAN\cite{mittal2019semi}& 18.3 & 96.69 && 62.6 & 98.15 && 70.8 & 98.60 && 76.4 & 98.96 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 51.7 & 97.71 && 62.0 & 98.16 && 66.7 & 98.28 && 75.9 & 98.93 \\ %40
      & RCR\cite{bandara2022RCR}& 65.8 & 98.37 && \underline{68.1} & \underline{98.47} && \cellcolor{mycyan}\textbf{74.8} & \underline{98.84} && \underline{77.2} & \underline{98.96} \\
      & FPA\cite{Zhang2023FPA}& \underline{66.3} & \underline{98.45} && 57.4 & 97.69 && 62.5 & 98.48 && 73.1 & 98.69 \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{67.8} & \textbf{98.62} && \textbf{70.8} & \textbf{98.70} && \cellcolor{white}\underline{74.7} & \textbf{98.86} && \textbf{79.6} & \textbf{99.13} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 85.5} and OA=\textcolor{red}{\bf 99.38}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{GZ-CD}
      & Sup. only   &   47.5 & 93.56 && 51.4 & 94.26 && 58.0 & 95.65 && 66.3 & 96.62 \\ %40
      & AdvEnt\cite{vu2019advent}& 48.6 & 94.39 && 50.9 & 94.89 && 60.2 & 95.79 && 66.2 & 96.58 \\ %40
      & s4GAN\cite{mittal2019semi}& 50.8 & 94.38 && 52.4 & 94.98 && 60.8 & 95.94 && 64.2 & 96.39 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 48.4 & 93.58 && 49.7 & 94.79 && 59.0 & 95.66 && 66.3 & 96.57 \\ %40
      & RCR\cite{bandara2022RCR}& 50.8 & 93.82 && 50.8 & 94.69 && 62.5 & 96.07 && 67.8 & 96.61 \\
      \rowcolor{mycyan}
      \multirow{-7}{*}{\cellcolor{white}}& \cellcolor{white}
      FPA\cite{Zhang2023FPA}& \cellcolor{white}51.2 & \cellcolor{white}93.92 && \textbf{58.9} & \textbf{95.78} && \textbf{63.1} & \textbf{96.26} && \textbf{68.2} & \textbf{96.82} \\
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \cellcolor{mycyan}\textbf{51.6} & \cellcolor{mycyan}\textbf{94.56} && \underline{57.1} & \underline{95.57} && \underline{62.4} & \underline{96.21} && \underline{68.0} & \underline{96.75} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 69.0} and OA=\textcolor{red}{\bf 96.93}} \\
      \bottomrule
      \multirow{8}{*}{EGY-CD}
      & Sup. only   &   49.8 & 95.73 && 54.6 & 96.38 && 61.4 & 96.83 && 65.1 & 97.25 \\ %40
      & AdvEnt\cite{vu2019advent}& 52.7 & 96.01 && 57.8 & 96.58 && 62.6 & 96.86 && 64.0 & 97.19 \\ %40
      & s4GAN\cite{mittal2019semi}& 52.9 & 95.94 && 58.6 & 96.50 && 64.7 & 97.09 && 64.9 & 97.27 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 52.4 & 96.00 && 57.9 & 96.31 && 62.8 & 96.95 && 63.8 & 97.19 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{58.1} & 96.50 && \underline{61.9} & 96.77 && 63.9 & 97.08 && 64.2 & 97.18 \\

      \multirow{-7}{*}{\cellcolor{white}}& \cellcolor{white}
      FPA\cite{Zhang2023FPA}& 57.5 & \underline{96.52} && 60.1 & \cellcolor{mycyan}\textbf{96.86} &\cellcolor{mycyan}& \cellcolor{mycyan}\textbf{65.2} & \cellcolor{mycyan}\textbf{97.25} && \underline{65.7} & \underline{97.34} \\

      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{59.0} & \textbf{96.55} && \textbf{60.5} & \cellcolor{white}\underline{96.80} & \cellcolor{white} & \cellcolor{white}\underline{65.0} & \cellcolor{white}\underline{97.20} & \cellcolor{white}& \textbf{67.4} & \textbf{97.39} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 67.6} and OA=\textcolor{red}{\bf 97.54}} \\
      \bottomrule
      \multirow{8}{*}{HRCUS-CD}
      & Sup. only   &   29.5 & 98.11 && 36.0 & 98.45 && 43.4 & 98.68 && 48.9 & 98.84 \\ %40
      & AdvEnt\cite{vu2019advent}& 29.1 & 98.11 && 36.9 & 98.40 && 42.5 & 98.61 && 48.8 & 98.71 \\ %40
      & s4GAN\cite{mittal2019semi}& 25.0 & 97.86 && 28.2 & 98.24 && 40.1 & 98.62 && 50.3 & 98.85 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 28.4 & 98.00 && 34.7 & 98.44 && 44.1 & 98.68 && 48.5 & 98.74 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{36.1} & 98.36 && 42.1 & \underline{98.69} && 45.3 & 98.76 && 49.6 & 98.66 \\

      & FPA\cite{Zhang2023FPA}& 35.2 & \underline{98.37} && \cellcolor{mycyan}\textbf{43.7} & 98.65 && \underline{46.7} & \underline{98.82} && \cellcolor{mycyan}\textbf{51.2} & \textbf{98.81} \\

      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &  \textbf{37.8} & \cellcolor{mycyan}\textbf{98.59} && \cellcolor{white}\underline{42.6} & \textbf{98.70} && \textbf{48.1} & \textbf{98.84} && \cellcolor{white}\underline{50.8} & \underline{98.87} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 59.0} and OA=\textcolor{red}{\bf 99.06}} \\
      \bottomrule
  \end{tabular}
  }
  \label{tab:AdaTh-building}
\end{table}
\subsection{消融实验}
\section{本章小结}

\chapter{基于伪标签评估的自适应半监督变化检测算法}
\section{引言}
变化检测是遥感的一个重要领域，其主要重点是确定卫星在同一区域以不同间隔拍摄的双时相图像对中的变化区域。考虑到为变化检测任务准确标注掩码的过程是劳动密集型的，半监督变化检测是更有前景的方法。半监督变化检测的范式通常是通过利用有限的可用标签和大量未标记的样本来提高变化检测性能。对未标记的数据生成伪标签，这些伪标签通常是具有较高预测概率的临时预测掩码，将其作为训练过程中的指导信号，通过混合训练具有实际标签的有限数据和具有伪标签的丰富数据，学生模型可以学习到更多重要的特征，从而显著提高性能。最流行的方法是平均教师\cite{Tarvainen2017teacher}框架，它使用一个教师模型来生成伪标签，在训练过程中为学生模型提供指导。随后使用学生模型的指数移动平均（EMA）更新教师模型。

虽然这些方法已经获得了一定的成功，但仍然存在重大问题：即模型以同样的方式处理所有样本，而不考虑不同样本之间必然存在的差异性，并且训练过程缺乏灵活性。首先，很明显，未标记的样本可能并不总是能够胜任“教师”角色。模型在为复杂的样本生成可靠的高质量伪标签时经常遇到困难，这反过来又引入了额外的噪声，可能会误导模型的训练。

此外，EMA更新过程也没有考虑这种噪声干扰。考虑到训练批次中可能存在偏差或包含噪声，动态确定训练更新有助于训练过程的稳定性。这些因素强调需要更精确的监督方法，否则可能会对模型的训练产生负面影响。在本研究中，我们引入了一种自适应动态学习策略AdaSemiCD，旨在提高伪标签的准确性并简化训练过程。我们的框架结合了传统的半监督训练方法，并辅以两个创新的功能模块AdaFusion和AdaEMA。首先，我们利用AdaFusion在单个样本水平上抑制噪声，从而提高伪标签的准确性。与之前依赖于完全随机融合区域的Augseg\cite{zhao2023AugSeg}或CutMix\cite{yun2019cutmix}等方法相反，我们的AdaFusion模块主动识别可能最不确定的区域，并将其替换为来自高质量标记数据集或未标记数据集的可靠内容。在此之后，我们通过AdaEMA模块动态调整师生模型的参数更新选择批次，以确保提高稳定性。虽然传统的EMA有效地减轻了模型参数的波动从而提高了稳定性，但它在每次训练迭代后都统一的更新参数，在处理一系列训练样本时忽略了模型在不同迭代中的不同学习效果。如果未标记的样本包含大量错误信息，它可能会误导模型的训练。因此，我们的AdaEMA引入了模型级参数更新的自适应选择过程，使模型能够充分集成优越的参数。

本章阐述了基于伪标签评估的自适应半监督变化检测算法，首先介绍了模型的整体框架以及训练流程，随后详细介绍了设计的伪标签评估指标，以及基于此指标设计的两个自适应模块。最后在实验部分报告了该研究方法在十个公开数据集上取得的实验结果，并与其他经典半监督变化检测算法在定性和定量两个维度进行了公平的对比，证明了我们的方法优越性。最后通过消融实验证明了每个模块的有效性。
\section{基于伪标签评估的自适应半监督变化检测框架}
\subsection{整体框架}
图\ref{fig:Adasemicd_fram}展示了AdaSemiCD总体框架。半监督变更检测的任务描述如下：给定一个标记数据集$D_{l}=\left\{\left\{x_{a, i}^{l}, x_{b, i}^{l}\right\}, y_{i}^{l}\right\}_{i=1}^{m}$,一个无标注数据集$D_{u}=\left\{x_{a, j}^{u}, x_{b, j}^{u}\right\}_{j=1}^{n}$，其中$\left\{\left\{x_{a, i}^{l}, x_{b, i}^{l}\right\}, y_{i}^{l}\right\}$代表第i个双时相图像对和真实标签，以及$\left\{x_{a, j}^{u}, x_{b, j}^{u}\right\}$代表第i对未标记图像对，下标a和b分别是用于标识双时相图像对的前、后时相的图像，标注数据集和无标注数据集的样本数量分别是n和m, 并且$n \gg m$，模型M不仅可以从$D_{l}$中提取有意义的信息，还可以通过利用$D_{u}$中大量未标记的训练样本来捕获更广泛的特征，以提高模型的泛化能力。

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.35]{images/AdaFrame.png}
  \caption{
    AdasemiCD的整体框架图。
  }
  \label{fig:Adasemicd_fram}
\end{figure}

\textbf{模型架构}：在本研究中，我们采用广泛应用的师生框架来完成半监督变化检测任务。该网络由两个组件组成，学生模型$M_{stu}$和教师模型$M_{tea}$具有相同的网络结构。通过梯度下降方法进行优化，训练学生模型从少量标记样本和大量未标记样本中提取变化特征。相反，而教师模型$M_{tea}$用于生成伪标签来指导学生学习未标记的数据，教师模型使用EMA方法更新参数。

无标记样本在输入到教师和学生网络之前会分别经历弱增强$A_{w}(\cdot)$以及进一步的强增强$A_{s}(\cdot)$过程，以提供输出一致性正则化项。

\textbf{训练目标}：目标是最小化模型在$D_{l}$上训练的监督损失$L_s$和在$D_{u}$上训练的无监督损失$L_u$。在训练过程中，样本以随机打乱的批次（$B_l$和$B_u$）的形式输入网络。一个小批次内在标记样本上的$L_s$损失计算为其预测概率$P_{i}^{l}$与真实标签$y_{i}^{l}$（Ground Truth，GT）之间的交叉熵（Cross Entropy， CE）：
\begin{equation}
  \label{eq:AdaLossS}
  \mathcal{L}_{s}=\frac{1}{\left|\mathcal{B}_{l}\right|} \sum_{i=1}^{\left|\mathcal{B}_{l}\right|} \mathrm{CE}\left(p_{i}^{l}, y_{i}^{l}\right)
\end{equation}

其中$\mathcal{B}_{l}$表示标记样本mini-batch的大小，$p_{i}^{l}$表示学生模型对第i对无标注图像对的预测概率。

一个批次内在未标记样本上的无监督损失$L_u$也类似，这里我们使用来自$M_{tea}$的伪标签作为监督，因此$L_u$计算为：
\begin{equation}
  \label{eq:AdaLossU}
  \mathcal{L}_{u}=\frac{1}{\left|\mathcal{B}_{u}\right|} \sum_{j=1}^{\left|\mathcal{B}_{u}\right|} \mathrm{CE}\left(p_{s, j}^{u}, \hat{y}^{u}_{i}\right)
\end{equation}
\begin{equation}
  \label{eq:pesudo}
  \hat{y}^{u}_{i}={\arg \max } \left(p_{w, j}^{u}\right)>\tau
\end{equation}
其中$\mathcal{B}_{u}$表示未标记样本mini-batch的大小，$p_{w, j}^{u}=M_{t e a}^{\theta^{\prime}}\left(w_{a, j}^{u}, w_{b, j}^{u}\right)$表示教师模型对第i对弱增强未标记图像对的变化的预测概率结果，进一步利用$\arg \max$算子对其进行取最大运算得到伪标签$\hat{y}^{u}_{i}$，如格式\ref{eq:pesudo}所示，$p_{s, j}^{u}=M_{s t u}^{\theta}\left(s_{a, j}^{u}, s_{b, j}^{u}\right)$表示教师模型对第i对强增强未标记图像对的变化检测预测概率，$\tau$为固定的筛选阈值，用于剔除低置信的预测。

综上所述，AdaSemiCD训练过程总的损失为：
\begin{equation}
  \label{eq:AdaLoss}
  \mathcal{L}=\mathcal{L}_{s}+\lambda(\cdot) \mathcal{L}_{u}
\end{equation}

以往的研究\cite{sohn2020fixmatch}\cite{transformation_medical}均采用固定值表示$\lambda(\cdot)$。然而，我们认为这种方法不适合单阶段半监督学习算法。在初始训练阶段，我们的模型对未标记的样本生成的伪标签是高度不可靠的；在这个阶段过度依赖无监督训练可能会引入严重的噪声。相反，随着训练进入中后期阶段，模型越来越多地从有限的标记数据中学习，伪标签的质量得到提高，这时减少监督训练相对于非监督训练的比例是合理的。为了减轻过拟合现象和增强特征空间，必须实现一个受控过程来动态调整这两个分量在损失函数中的贡献。我们使用一个预热过程来控制未标记部分的训练速度。$\lambda(\cdot)$为无监督损失随训练步长变化的权值，用于动态调整不同阶段有监督和无监督训练的比例，表达式如\ref{eq:ramp-up}所示。
\begin{equation}
  \label{eq:ramp-up}
  \lambda(\cdot)=w_{\max } \times e^{-\phi \times\left(1-\text { iter }_{\text {cur }} / \text { iter }_{\max }\right)^{2}}
\end{equation}

其中$w_{\max }$和$\phi$是超参数，$w_{\max }$表示无监督损失的最大可达权重，$\phi$用于控制上升的剧烈程度；$\text { iter }_{\text {cur }}$表示当前迭代周期；$\text { iter }_{\text {max }}$为预热过程的总步长，由$\gamma$与总训练迭代次数相乘得到，且$0<\gamma<1.0$；在上升过程之后，无监督损失的权重保持为$w_{\max }$不变。在训练的早期，该权值相对较低，无监督训练的作用可以忽略不计，但在训练的中后期，该权值逐渐增大，加权后的无监督损失超过了有监督损失，因此无监督训练占主导。

\textbf{训练策略}：学生网络的参数$\theta$通过随机梯度下降（SGD）技术来调整，以最小化总体损失$\mathcal{L}$，而教师网络的参数$\theta'$通过学生模型参数$\theta$在训练时间序列上的指数移动平均来更新，如\ref{eq:ema}所示。超参数$\beta$作为动量参数，$\beta$值越大，移动指数平均的窗口越宽。通常，$\beta$选择接近1.0的数字，例如在本研究中，选择0.996。
\begin{equation}
  \label{eq:ema}
  \theta^{\prime}=\beta \theta^{\prime}+(1-\beta) \theta
\end{equation}

\textbf{自适应模块}：半监督学习的本质在于伪标签的质量。然而，很明显，前面提到的过程没有考虑到不同样本个体对模型训练的不同影响。本章研究主要关注与伪标签生成直接相关的两个元素：未标记图像对，以及伪标签生成网络（即教师模型）在识别变化方面的性能。为了给未标记信息提供更可靠的监督指导，减少训练的不确定性，我们设计了一种自适应训练策略来解决这两个关键问题。我们首先设计了一个度量标准，用于量化伪标签的不确定性，作为自适应调整的基础。接下来，我们提出图像层面对未标记的训练样本进行自适应改造。此外，还提出在训练阶段对教师网络应用自适应选择性的EMA更新，以集成更加正确的参数，从而产生更一致和更高质量的伪标签。这些努力将在下面的小节中进行详细阐述。
\subsection{伪标签评估指标设计}
为了通过准确测量伪标签的质量来提高其有效性，关键的一步就是评估指标的设计。这个度量将有助于识别可靠的标签和确定每个训练样本的效力。与带有标记图像对的场景不同，可以将真实标签作为基准，通过预测与真是标签的平均交并比、F1分数等来评估模型的推理质量，而伪标签缺乏任何这样的参考，其只能与自己进行比较。

因此，我们专门为伪标签设计了一个可量化的评估指标，旨在总体信息熵的基础之上，同时考虑到类别不平衡和混淆区域等因素。信息熵是一种衡量模型性能的常用指标，计算公式如下：
\begin{equation}
  \label{eq:entropy}
  E\left(x_{i}\right)=-P\left(x_{i}\right) \log _{2} P\left(x_{i}\right)
\end{equation}

其中$P\left(x_{i}\right)$为模型对于样本$x_{i}$的输出概率。我们认为，预测值中的信息熵越低，预测结果的可信度越高。相反，信息熵越高，预测结果的变化越大，同一像素上的预测概率分布越均匀，类别之间的差异越小。
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.25]{images/imbalance.png}
  \caption{
    公开变化检测数据集的标注类别统计。
  }
  \label{fig:Adasemicd_imbalance}
\end{figure}
在变化检测任务中，由于类别不平衡带来的巨大挑战，直接应用信息熵通常不会产生良好的结果。如图\ref{fig:Adasemicd_imbalance}所示，我们在10个公开的变化检测数据集上进行了统计分析，变化和不变类别的比例是极度失衡的。这种类别不平衡现象会导致模型在训练过程中学习目标类别不够充分，而过度地拟合不变类别的特征分布。因此，在推理过程中，模型更倾向于将像素分类为背景类。因此，尽管该模型的总体精度（OA）看起来很高，但在目标类别的交并比（$IoU_c$）上的性能仍然令人不满意。为了在评估伪标签质量时最大限度地减少这种类别不平衡的影响，我们在计算信息熵时为两个类别分配了不同的权重，如\autoref{eq:balance}所示。
\begin{equation}
  \label{eq:balance}
  E^{\prime}(X)=w_{1} \times E\left(x_{i}\right)[0]+w_{0} \times E\left(x_{i}\right)[1]
\end{equation}

其中$w_{0}$和$w_{0}$分别表示当前小批次中属于不变类和变化类别的像素的比例。其计算公式如\autoref{eq:w0}和\autoref{eq:w1}所示。
\begin{equation}
  \label{eq:w0}
  w_{0}=\frac{\sum_{i=1}^{|B u|} \sum_{k=1}^{H \times W}\left(P\left(x_{i}\right)==0\right)}{|B u| \times H \times W}
\end{equation}
\begin{equation}
  \label{eq:w1}
  w_{1}=\frac{\sum_{i=0}^{|B u|} \sum_{k=0}^{H \times W}\left(P\left(x_{i}\right)==0\right)}{|B u| \times H \times W}
\end{equation}

此外，来自边界、目标与背景相似的区域的像素，模型的预测通常具有很大的不确定性，应该得到更多的重视。首先，我们通过计算两类预测概率之差的绝对值来增强这些易混区域的影响:
\begin{equation}
  \label{eq:abs}
  D\left(x_{i}\right)=\operatorname{abs}\left(P\left(x_{i}\right)[1]-P\left(x_{i}\right)[0]\right)
\end{equation}

这里，$\operatorname{abs}$表示取绝对值运算，这是一种用来防止前后时相变化检测不幂问题的措施。然后利用信息熵进行逐像素相乘运算，最终得到图像的不确定性映射图$U\left(x_{i}\right)$：
\begin{equation}
  \label{eq:uncertainty}
  U\left(x_{i}\right)=1-D\left(x_{i}\right) \cdot E^{\prime}\left(x_{i}\right)
\end{equation}

显然，在低信息熵的像素位置，该过程不会导致显著的变化，而在高信息熵的像素位置，其值将显著减小，直接使用该指标与所表达的意义相反。因此，我们采用校正信息熵的逆作为其描述。

综上所述，为了评估变化检测伪标签的质量，我们提出了一个可量化的计算度量$U$来衡量预测不确定性，该度量考虑了类别不平衡等因素并增加了对混淆区域的关注，从而在总体信息熵的基础上表达了更多有价值的信息。
\subsection{自适应样本融合机制}
图像融合经常被用来增强或者改造训练样本以提高样本多样性，CutMix\cite{yun2019cutmix}和MixUp\cite{zhang2017mixup}是典型的融合方法。在本研究中，我们的目标是利用图像融合技术来排除训练样本中的不可靠区域。这个过程包括两个步骤：1）融合区域选择；2）融合图像选择。

\textbf{融合区域的自适应选择}。与传统的随机选择混合区域的CutMix技术不同，我们的方法更加精细。首先我们将初始化一个随机大小的边界框，然后沿着图像坐标滑动窗口，维护一个总体最大不确定性框，最终选择总体不确定性最高的区域作为融合区域。

这些区域通常是边界或复杂的区域，模型在这些区域的检测性能受限，很难准确识别变化目标，因此如果不做处理地直接用于训练，就会引入大量的噪声干扰，这对模型训练有很大的影响。

\textbf{融合内容的自适应选择}。对于最大不确定性的区域，我们可以选择从样本集中选择一个其余更可信的样本替代这部分，可选样本来自标记数据集$B_l$或y有着更高可靠性的未标记数据集$B_u$。这种策略可以防止过度使用仅有的少量标记样本，进一步降低过拟合的风险。这里融合内容使用图像块而不使用实例对象，这是因为我们认为过多的人为干预可能会破坏模型的泛化能力，并且仅替换实例对象可能造成周围像素的失真。

融合内容的选择主要通过自适应调整决策上界来确定融合内容。我们直接使用同一个小批次内计算的不确定性均值作为决策上界，对每个小批次随机生成一个概率值（0到1之间），如果超过不确定性均值，代表当前样本包含的噪声过多，则随机从标记图像批次中选择一对图像作为融合内容。我们会维护根据不确定性排序维护一个批次不确定性队列集合，如果小于此上界，则从此队列集合中均匀选择TopK的未标记的图像对。很容易理解，无标注样本的伪标签质量越高。可以被认为足够可靠。而不确定性越高的样本噪声越大，融合标记样本可以显著降低噪声密度，融合过程如图\ref{fig:Adasemicd_fram}左下角的AdaFusion子图。
\subsection{自适应师生模型参数更新机制}
在平均教师框架中，通过对学生模型参数在时间序列上的移动指数平均得到教师模型的参数，这种方法与共享权重的孪生网络相比，更加稳定可靠。然而，我们对平均教师模型的期望是达到共同进化的最优状态，在这种状态下，教师模型是不断进化的学生模型的累积表示。实现这种共同进化的关键因素是每次教师模型更新时，学生模型是处于更优状态还是处于波动状态。那么，我们如何评估学生模型的状态呢？这个问题本质上与训练过程的验证阶段类似。通常，在训练几个epoch后，我们评估当前模型，将验证集中的样本输入到模型中进行推理，并将结果与实际标签进行比较以确定模型的表现。然而，如果我们在每次迭代之后都进行这样的验证过程，那样是非常耗费计算资源的，导致训练时间的显著增加，这是一种不现实的方案。降低验证集中的样本数量（仅为几对）可能会解决可行性问题，但样本量太小无法全面准确地评估模型的性能，这会带来新的挑战。那么，有没有一种方法可以将这两个概念融合在一起呢？

\begin{algorithm}[tb]
  \caption{The AdaEMA algorithm.}
  \label{alg:AdaEMA}
  \begin{algorithmic}[1] % 这个1 表示每一行都显示数字
    \Require ~~\\
    Student model $M_{stu}^{\theta}$, Teacher model $M_{tea}^{\theta'}$ \\
    The set of training samples for current batch $\mathcal{B} = \left \{\mathcal{B}_l, \mathcal{B}_u\right \}$ \\
  \Ensure ~~\\
    Updated Teacher model, $M_{tea}^{\hat{\theta}}$ \\
  \State Calculate the loss $\mathcal{L}_{s}$ on labeled samples $\mathcal{B}_l$ with Eq.~\ref{eq:AdaLossS};
  \State Calculate the loss $\mathcal{L}_{u}$ on unlabeled samples $\mathcal{B}_u$ with Eq.~\ref{eq:AdaLossU};
  \State Update the student model $M_{stu}^{\theta}$ to $M_{stu}^{\theta'}$ by SGD to minimize the total loss following Eq.~\ref{eq:AdaLoss};
  \State Calculate the uncertainty ${U}_{tea}$ of pseudo-labels generated on $\mathcal{B}_u$ by the teacher model $M_{tea}^{\theta'}$ according to Eq.~\ref{eq:uncertainty};
  \State Calculate the uncertainty ${U}_{stu}$ on $\mathcal{B}_u$ by updated student model $M_{stu}^{\theta'}$ according to Eq.~\ref{eq:uncertainty};
  \State Calculate the upper bound on the probability of update $\tau$ according to Eq.~\ref{eq:varepsilon} and Eq.~\ref{eq:tau};
  \If{$random(\cdot)<\tau$}
    \State Update the teacher model to $M_{tea}^{\hat{\theta}}$ by Eq.~\ref{eq:ema};
  \Else
    \State $M_{tea}^{\hat{\theta}} = M_{tea}^{\theta'}$;
  \EndIf
  \State \textbf{Return:} $M_{tea}^{\hat{\theta}}$;
  \end{algorithmic}
\end{algorithm}
\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.30]{images/vis_plot.png}
  \caption{
    AdaSemiCD与SOTA方法在10个数据集上的性能对比折线图。
  }
  \label{fig:iou_plot}
\end{figure}
在每个训练阶段，我们首先根据第3.3.1小节中描述的训练策略更新学生模型的参数$M^{\theta}_{stu}$，从而得到$M^{\theta'}_{stu}$。接下来，我们在当前的未标记训练样本批次$B_u$上评估更新后的学生模型$M^{\theta'}_{stu}$和教师模型$M^{\theta}_{tea}$。我们根据\ref{eq:uncertainty}计算不确定性图，并将其分别表示为$U_{tea}$和$U_{stu}$。进一步根据\ref{eq:varepsilon}得到不确定性变化值$\varepsilon$。
\begin{equation}
  \label{eq:varepsilon}
  \varepsilon=\frac{\sum U_{s t u}-\sum U_{\text {tea }}}{\left|B_{u}\right|}
\end{equation}

如果$\varepsilon < 0$，则代表模型性能发生退化或处于振荡。相反，当$\varepsilon \geqslant 0$，模型得到正确的训练。最终，只有进化的学生模型被选择参与到教师模型参数的更新中，为了加入一定的动态性，我们据此得到一个更新概率上界，如\autoref{eq:tau}所示，再根据此上界决策此迭代轮次是否更新。
\begin{equation}
  \label{eq:tau}
  \tau=\left\{\begin{array}{ccc}
    \frac{1}{\text { iter }^{2}+\epsilon} & , & \varepsilon \leq 0 \\
    1.0 & , & \varepsilon>0
    \end{array}\right.
\end{equation}

这里，$\epsilon=1e-5$用来防止除数为零，$iter$表示当前的迭代计数。如果模型不确定性变化值$\varepsilon \leqslant 0$，也不会完全丢弃它们。而是赋予一个较低的概率上界去选择更新。有了这个上限规则（范围从0到1），引入了一些随机性来确定教师网络参数更新，进一步的细节可以在算法\ref{alg:AdaEMA}中找到。
\section{实验结果及分析}
\begin{table}[!htbp]
  \centering
  % \tiny
  \scriptsize
  \caption{不同CD方法在二值建筑物变化检测数据集上的平均定量性能对比。}
  \resizebox{0.8\textwidth}{!}{
  \begin{tabular}{p{20mm}p{20mm}p{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}} %
      \toprule
      \multirow{2}{*}{Dataset} & \multirow{2}{*}{\parbox[c]{.2\linewidth}{Method}} & \multicolumn{2}{c}{5\%} & & \multicolumn{2}{c}{10\%} & & \multicolumn{2}{c}{20\%} & & \multicolumn{2}{c}{40\%}\\
      \cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10} \cmidrule{12-13}
      & & {$IoU^c$} & {OA} && {$IoU^c$} & {OA} & & {$IoU^c$} & {OA} &&{$IoU^c$} & {OA}\\
      \midrule
      \multirow{8}{*}{LEVIR-CD}
      & Sup. only   &   61.0 & 97.60 && 66.8 & 98.13 && 72.3 & 98.44 && 74.9 & 98.60 \\ %40
      & AdvEnt\cite{vu2019advent}& 66.1 & 98.08 && 72.3 & 98.45 && 74.6 & 98.58 && 75.0 & 98.60 \\ %40
      & s4GAN\cite{mittal2019semi}& 64.0 & 97.89 && 67.0 & 98.11 && 73.4 & 98.51 && 75.4 & 98.62 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 67.6 & 98.17 && 71.5 & 98.42 && 74.3 & 98.58 && 75.5 & 98.63 \\ %40
      & RCR\cite{bandara2022RCR}& 72.5 & 98.47 && 75.5 & 98.63 && 76.2 & 98.68 && 77.2 & 98.72 \\
      & FPA\cite{Zhang2023FPA}& \underline{73.7} & \underline{98.57} && \underline{76.6} & \underline{98.72} && \underline{77.4} & \underline{98.75} && \underline{77.0} & \underline{98.74} \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{77.7} & \textbf{98.78} && \textbf{79.4} & \textbf{98.87} && \textbf{80.3} & \textbf{98.92} && \textbf{80.6} & \textbf{98.93} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 77.9} and OA=\textcolor{red}{\bf 98.77}} \\
      \bottomrule
      %\midrule
      \multirow{8}{*}{LEVIR-CD+}
      & Sup. only   &   52.0 & 97.72 && 58.4 & 98.06 && 66.1 & 98.31 && 66.2 & 98.42 \\ %40
      & AdvEnt\cite{vu2019advent}& 52.2 & 97.68 && 59.9 & 98.11 && 65.9 & 98.37 && 68.0 & 98.51 \\ %40
      & s4GAN\cite{mittal2019semi}& 46.5 & 97.25 && 51.4 & 97.66 && 62.8 & 98.18 && 67.2 & 98.46 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 52.6 & 97.66 && 60.7 & 98.24 && 64.8 & 98.37 && 66.1 & 98.38 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{64.9} & 98.25 && \underline{67.5} & \underline{98.45} && 68.5 & 98.52 && 68.4 & 98.51 \\
      & FPA\cite{Zhang2023FPA}& 64.6 & \underline{98.30} && 67.3 & 98.40 && \underline{70.3} & \cellcolor{mycyan}\textbf{98.64} && \underline{69.0} & \underline{98.59} \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{66.7} & \textbf{98.49} && \textbf{68.8} & \textbf{98.51} && \textbf{70.6} & \cellcolor{white}\underline{98.63} && \textbf{70.9} & \textbf{98.64} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 70.5} and OA=\textcolor{red}{\bf 98.63}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{WHU-CD}
      & Sup. only   &   50.0 & 97.48 && 55.7 & 97.53 && 65.4 & 98.20 && 76.1 & 98.94 \\ %40
      & AdvEnt\cite{vu2019advent}& 55.1 & 97.90 && 61.6 & 98.11 && 73.8 & 98.80 && 76.6 & 98.94 \\ %40
      & s4GAN\cite{mittal2019semi}& 18.3 & 96.69 && 62.6 & 98.15 && 70.8 & 98.60 && 76.4 & 98.96 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 51.7 & 97.71 && 62.0 & 98.16 && 66.7 & 98.28 && 75.9 & 98.93 \\ %40
      & RCR\cite{bandara2022RCR}& 65.8 & 98.37 && \underline{68.1} & \underline{98.47} && \cellcolor{mycyan}\textbf{74.8} & \underline{98.84} && \underline{77.2} & \underline{98.96} \\
      & FPA\cite{Zhang2023FPA}& \underline{66.3} & \underline{98.45} && 57.4 & 97.69 && 62.5 & 98.48 && 73.1 & 98.69 \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{67.8} & \textbf{98.62} && \textbf{70.8} & \textbf{98.70} && \cellcolor{white}\underline{74.7} & \textbf{98.86} && \textbf{79.6} & \textbf{99.13} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 85.5} and OA=\textcolor{red}{\bf 99.38}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{GZ-CD}
      & Sup. only   &   47.5 & 93.56 && 51.4 & 94.26 && 58.0 & 95.65 && 66.3 & 96.62 \\ %40
      & AdvEnt\cite{vu2019advent}& 48.6 & 94.39 && 50.9 & 94.89 && 60.2 & 95.79 && 66.2 & 96.58 \\ %40
      & s4GAN\cite{mittal2019semi}& 50.8 & 94.38 && 52.4 & 94.98 && 60.8 & 95.94 && 64.2 & 96.39 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 48.4 & 93.58 && 49.7 & 94.79 && 59.0 & 95.66 && 66.3 & 96.57 \\ %40
      & RCR\cite{bandara2022RCR}& 50.8 & 93.82 && 50.8 & 94.69 && 62.5 & 96.07 && 67.8 & 96.61 \\
      \rowcolor{mycyan}
      \multirow{-7}{*}{\cellcolor{white}}& \cellcolor{white}
      FPA\cite{Zhang2023FPA}& \cellcolor{white}51.2 & \cellcolor{white}93.92 && \textbf{58.9} & \textbf{95.78} && \textbf{63.1} & \textbf{96.26} && \textbf{68.2} & \textbf{96.82} \\
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \cellcolor{mycyan}\textbf{51.6} & \cellcolor{mycyan}\textbf{94.56} && \underline{57.1} & \underline{95.57} && \underline{62.4} & \underline{96.21} && \underline{68.0} & \underline{96.75} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 69.0} and OA=\textcolor{red}{\bf 96.93}} \\
      \bottomrule
      \multirow{8}{*}{EGY-CD}
      & Sup. only   &   49.8 & 95.73 && 54.6 & 96.38 && 61.4 & 96.83 && 65.1 & 97.25 \\ %40
      & AdvEnt\cite{vu2019advent}& 52.7 & 96.01 && 57.8 & 96.58 && 62.6 & 96.86 && 64.0 & 97.19 \\ %40
      & s4GAN\cite{mittal2019semi}& 52.9 & 95.94 && 58.6 & 96.50 && 64.7 & 97.09 && 64.9 & 97.27 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 52.4 & 96.00 && 57.9 & 96.31 && 62.8 & 96.95 && 63.8 & 97.19 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{58.1} & 96.50 && \underline{61.9} & 96.77 && 63.9 & 97.08 && 64.2 & 97.18 \\

      \multirow{-7}{*}{\cellcolor{white}}& \cellcolor{white}
      FPA\cite{Zhang2023FPA}& 57.5 & \underline{96.52} && 60.1 & \cellcolor{mycyan}\textbf{96.86} &\cellcolor{mycyan}& \cellcolor{mycyan}\textbf{65.2} & \cellcolor{mycyan}\textbf{97.25} && \underline{65.7} & \underline{97.34} \\

      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{59.0} & \textbf{96.55} && \textbf{60.5} & \cellcolor{white}\underline{96.80} & \cellcolor{white} & \cellcolor{white}\underline{65.0} & \cellcolor{white}\underline{97.20} & \cellcolor{white}& \textbf{67.4} & \textbf{97.39} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 67.6} and OA=\textcolor{red}{\bf 97.54}} \\
      \bottomrule
      \multirow{8}{*}{HRCUS-CD}
      & Sup. only   &   29.5 & 98.11 && 36.0 & 98.45 && 43.4 & 98.68 && 48.9 & 98.84 \\ %40
      & AdvEnt\cite{vu2019advent}& 29.1 & 98.11 && 36.9 & 98.40 && 42.5 & 98.61 && 48.8 & 98.71 \\ %40
      & s4GAN\cite{mittal2019semi}& 25.0 & 97.86 && 28.2 & 98.24 && 40.1 & 98.62 && 50.3 & 98.85 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 28.4 & 98.00 && 34.7 & 98.44 && 44.1 & 98.68 && 48.5 & 98.74 \\ %40
      & RCR\cite{bandara2022RCR}& \underline{36.1} & 98.36 && 42.1 & \underline{98.69} && 45.3 & 98.76 && 49.6 & 98.66 \\

      & FPA\cite{Zhang2023FPA}& 35.2 & \underline{98.37} && \cellcolor{mycyan}\textbf{43.7} & 98.65 && \underline{46.7} & \underline{98.82} && \cellcolor{mycyan}\textbf{51.2} & \textbf{98.81} \\

      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &  \textbf{37.8} & \cellcolor{mycyan}\textbf{98.59} && \cellcolor{white}\underline{42.6} & \textbf{98.70} && \textbf{48.1} & \textbf{98.84} && \cellcolor{white}\underline{50.8} & \underline{98.87} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 59.0} and OA=\textcolor{red}{\bf 99.06}} \\
      \bottomrule
  \end{tabular}
  }
  \label{tab:Ada-building}
\end{table}
\subsection{实验设置}
\textbf{数据划分}：我们对所有数据集遵循相同的标记比例划分设置，我们选择5$\%$，10$\%$，20$\%$和40$\%$作为标记样本的比例，此比例表示我们将整个训练集的这部分样本视作有标记训练样本，其余样本我们仅使用训练图像对而不使用相应的真实标签，即视作无标记样本。其中在LEVIR-CD和WHU-CD上我们遵循\cite{bandara2022RCR}\cite{Zhang2023FPA}中的半监督划分，并对其他数据集执行我们自己的随机划分，但我们对于所有对比实验都是使用此相同的训练样本集进行公平的实验对比。

\textbf{实现细节}：为了防止网络结构带来的性能差异影响我们的结论，我们所有对比方法均使用ResNet50+PPM（Pyramid pooling module，特征金字塔池化模型）作为我们的变化检测网络。我们将初始学习率设置为0.01，它以0.9的动量随训练进程逐渐线性降低到1e-4，并使用SGD优化器训练所有方法。所有的模型都进行了80个epoch的训练，每个批次的标记和未标记mini-batch大小均设置为8。此外，所采用的所有数据增强方式都与\cite{Zhang2023FPA}中使用的增强方式相同，其中弱增强包括随机翻转、随机缩放、随机裁剪，强增强包括\cite{cubuk2020randaugment}中引用的9种强增强方式。由于标记数据的数量有限，模型对伪标签的过滤阈值非常敏感，在之前的研究中\cite{Zhang2023FPA}已经对阈值大小进行了消融研究，因此我们在对10个数据集进行的实验中将所有模型的阈值$\tau$按照经验都设置为0.95，并根据\cite{bandara2022RCR}$\phi$设置为5。我们所有的实验均利用PyTorch框架实现并且在4块NVIDIA GeForce RTX 3090 gpu上进行模型训练。
\subsection{对比试验}
我们与几种最先进的半监督变化检测方法进行了比较，其中SemiCDNet\cite{peng2021SemiCDNet}、RCR\cite{bandara2022RCR}和FPA\cite{Zhang2023FPA}是过去几年出现的获得最优性能的半监督变化检测方法。此外，我们还比较了两种半监督语义分割方法，s4GAN\cite{mittal2019semi}和AdvEnt\cite{vu2019advent}。
\subsubsection{定量对比}
我们在所有10个数据集上进行了实验，表\ref{tab:Ada-building}和表\ref{tab:Ada-mutil}分别报告了我们在建筑物变化检测数据集和多类变化检测数据集上的实验结果。其中，表中的Sup.Only是指仅在有限的标记数据集上进行监督训练，而Oracle是在整个全部训练数据集上进行全监督训练的结果。另外图\ref{fig:iou_plot}更直观地展示了我们的所有实验定量结果。值得注意的是，我们的方法在所有数据集的几乎所有半监督划分设置中都实现了最先进的性能。可以肯定的是，在大多数情况下，所有的半监督变化检测方法在相应的划分设置下都比监督方法表现得更好，这证明了半监督方法在从大量未标记的训练样本中学习到了更多的知识，同时，我们的方法取得的领先证明了我们对于如何高效、正确地从未标记样本集中学习的自适应机制是具有实际意义的。

\textbf{建筑物变化检测}:
如表\ref{tab:Ada-building}所示，其中蓝色高亮部分代表着最优结果，下划线标注的是次优结果。我们的AdaSemiCD在其中4个数据集上实现了最先进的性能，LEVIR-CD、LEVIR-CD+、WHU-CD和HRCUS-CD上的平均$IoU_c$分别提高了3.1、1.3、1.7和0.4个百分点。GZ-CD和EGY-CD在某些实验设置上取得的性能略低于FPA\cite{Zhang2023FPA}，但在标记数据极其稀缺的5$\%$标记率情况下仍能获得最佳结果，在其他一些实验设置下也能获得次优结果。不可忽视的是，我们的方法在LEVIR-CD、LEVIR-CD+和EGY-CD上仅使用10$\%$或20$\%$的标记数据就达到甚至超过了完全监督训练的结果，因为这些建筑物变化检测数据集中的样本类别是非常不平衡的，我们的方法考虑到了这一点。并且其变化区域比较规则，变化类型比较单一，我们的方法能够生成足够可靠的高质量伪标签。FPA\cite{Zhang2023FPA}的实验结果也证明了这一点，可以观察到相同的趋势，其中标记率在10$\%$到40$\%$之间实验结果并没有显著增加。
\begin{table}[!htbp]
  \centering
  % \tiny
  \scriptsize
  \caption{不同CD方法在多类变化检测数据集上的平均定量性能对比。}
  \resizebox{0.8\textwidth}{!}{
    \begin{tabular}{p{20mm}p{20mm}p{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}cp{8mm}p{8mm}} %
      \toprule
      \multirow{2}{*}{Dataset} & \multirow{2}{*}{\parbox[c]{.2\linewidth}{Method}} & \multicolumn{2}{c}{5\%} & & \multicolumn{2}{c}{10\%} & & \multicolumn{2}{c}{20\%} & & \multicolumn{2}{c}{40\%}\\
      \cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10} \cmidrule{12-13}
      & & {$IoU^c$} & {OA} && {$IoU^c$} & {OA} & & {$IoU^c$} & {OA} &&{$IoU^c$} & {OA}\\
      \midrule
      \multirow{8}{*}{CDD-CD}
      & Sup. only   &   60.4 & 94.25 && 67.9 & 95.46 && 75.6 & 96.59 && 82.3 & 97.56 \\ %40
      & AdvEnt\cite{vu2019advent}& 63.3 & 94.65 && 71.2 & 96.01 && 79.3 & 97.14 && \underline{82.9} & \underline{97.66} \\ %40
      & s4GAN\cite{mittal2019semi}& 62.3 & 94.69 && 71.0 & 95.94 && 79.0 & 97.10 && 82.8 & 97.63 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 63.5 & 94.68 && 71.2 & 95.99 && 79.1 & 97.13 && 82.8 & 97.63 \\ %40
      & RCR\cite{bandara2022RCR}& 67.6 & 95.40 && \underline{75.5} & \underline{96.57} && \underline{80.2} & \underline{97.26} && 82.7 & 97.61 \\
      & FPA\cite{Zhang2023FPA}& \underline{68.9} & \underline{95.66} && 74.9 & 96.55 && 79.7 & 97.20 && 81.1 & 97.37 \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{70.1} & \textbf{95.89} && \textbf{77.3} & \textbf{96.89} && \textbf{82.1} & \textbf{97.56} && \textbf{83.9} & \textbf{97.80} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 87.8} and OA=\textcolor{red}{\bf 98.10}} \\
      \bottomrule
      %\midrule
      \multirow{8}{*}{DSIFN-CD}
      & Sup. only   &   34.8 & 78.34 && \underline{38.9} & 83.41 && 40.2 & 87.00 && 39.6 & 87.00 \\ %40
      & AdvEnt\cite{vu2019advent}& 31.8 & 77.83 && 36.3 & 83.86 && 40.8 & 85.92 && 37.4 & 86.31 \\ %40
      & s4GAN\cite{mittal2019semi}& 36.6 & \underline{84.10} && 34.8 & \underline{86.87} && 37.9 & \cellcolor{mycyan}\textbf{87.69} && \underline{40.1} & 86.52 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 33.6 & 78.60 && 37.9 & 84.18 && 39.1 & 86.77 && 39.1 & \underline{87.05} \\ %40
      & RCR\cite{bandara2022RCR}& 26.7 & 83.78 && 32.9 & 86.05 && 40.8 & 86.70 && 36.7 & 86.08 \\
      & FPA\cite{Zhang2023FPA}& \cellcolor{mycyan}\textbf{39.2} & \cellcolor{mycyan}\textbf{84.27} && 38.5 & \cellcolor{mycyan}\textbf{87.12} && 36.0 & \underline{87.41} && 35.8 & 86.50 \\
      % \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \cellcolor{white}\underline{36.9} & \cellcolor{white}80.46 && \cellcolor{mycyan}\textbf{39.2} & 82.94 && \cellcolor{mycyan}\textbf{41.1} & 85.45 && \cellcolor{mycyan}\textbf{45.1} & \cellcolor{mycyan}\textbf{87.12} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 37.1} and OA=\textcolor{red}{\bf 86.82}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{SYSU-CD}
      & Sup. only   &   62.9 & 89.57 && 64.4 & 90.18 && 66.0 & 90.82 && 66.4 & 90.93 \\ %40
      & AdvEnt\cite{vu2019advent}& 61.2 & 89.36 && 64.5 & 90.18 && 65.7 & 90.35 && 68.3 & 91.24 \\ %40
      & s4GAN\cite{mittal2019semi}& 64.4 & 90.02 && 66.5 & 90.48 && 66.9 & 90.26 && 68.2 & 91.51 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 61.7 & 89.32 && 64.8 & 90.25 && 66.7 & 90.97 && 67.0 & 91.08 \\ %40
      & RCR\cite{bandara2022RCR}& 62.5 & 89.76 && 66.0 & 90.75 && 64.1 & 90.22 && 65.3 & 90.56 \\
      & FPA\cite{Zhang2023FPA}& \cellcolor{mycyan}\textbf{67.7} & 90.95 && \underline{68.3} & \underline{91.09} && \underline{70.1} & \underline{92.01} && \underline{69.3} & \cellcolor{mycyan}\textbf{91.97} \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \cellcolor{white}\underline{67.5} & \textbf{91.16} && \textbf{68.7} & \textbf{91.59} && \textbf{70.1} & \textbf{92.03} && \textbf{69.9} & \cellcolor{white}\underline{91.90} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 77.9} and OA=\textcolor{red}{\bf 98.77}} \\
      \bottomrule
      % \midrule
      \multirow{8}{*}{CL-CD}
      & Sup. only   &   18.1 & 91.90 && 31.4 & 92.42 && 37.2 & 93.32 && 45.9 & \underline{94.98} \\ %40
      & AdvEnt\cite{vu2019advent}& 24.3 & 92.13 && 33.2 & 93.01 && 37.6 & 93.59 && 42.9 & 94.06 \\ %40
      & s4GAN\cite{mittal2019semi}& 22.1 & 92.00 && 26.6 & 93.09 && 37.4 & 93.59 && 43.4 & 93.87 \\
      & SemiCDNet\cite{peng2021SemiCDNet} & 24.0 & \underline{92.20} && 28.3 & \underline{93.42} && 36.2 & 92.41 && 45.3 & 94.22 \\ %40
      & RCR\cite{bandara2022RCR}& 27.1 & 91.63 && 32.8 & 92.99 && 36.4 & 93.07 && \underline{48.5} & 94.94 \\
      & FPA\cite{Zhang2023FPA}& \underline{29.0} & 91.00 && \cellcolor{mycyan}\textbf{38.2} & \cellcolor{mycyan}\textbf{93.37} && \underline{39.6} & \underline{93.88} && 43.1 & 94.15 \\
      \rowcolor{mycyan}
      \multirow{-8}{*}{\cellcolor{white}}& \cellcolor{white}AdaSemiCD   &   \textbf{30.6} & \textbf{92.52} && \cellcolor{white}\underline{33.5} & \cellcolor{white}{92.40} && \textbf{41.6} & \textbf{94.21} && \textbf{49.1} & \textbf{95.85} \\%40
      \cline{2-13}
      & Oracle & \multicolumn{11}{c}{$ IoU^c$=\textcolor{red}{\bf 77.9} and OA=\textcolor{red}{\bf 98.77}} \\
      \bottomrule
  \end{tabular}
  }
  \label{tab:Ada-mutil}
\end{table}

此外，从实验结果来看，由于背景类占多数，所有方法在这些二值建筑物变化检测数据集上的总体准确率（OA）都很高。OA往往直接映射着平均交并比$IoU_c$， 即便是小幅度的OA提升，$IoU_c$就会有比较明显的改善。我们的AdaSemiCD在所有数据集上几乎都提高了预测的总体准确率，因为它极大地消除了噪声和错误信号的引导。

\textbf{多类变化检测}:
如表\ref{tab:Ada-mutil}所示，我们的AdaSemiCD同样在几乎所有多类数据集和所有划分设置上都实现了最佳性能，只是提升程度低于在简单的建筑物变化检测数据集上所取得的，这是由于多类别变化检测任务本身的复杂性，最明显的一点是，在某些情况下，之前的一些半监督的变化检测方法完全失效了，比监督基线的检测性能更差。然而，我们的半监督变化检测方法仍然可以利用额外的未标记样本来提高性能。

另一点值得注意的是，在这些多类变化检测数据集中，所有方法的整体精度都降低了，$OA$和$Iou_c$不再直接对应。其中一个现象是$Iou_c$达到了最高，而OA没有，这是由于其侧重点不同。OA更注重全局精度，在背景类占主导的数据集下就是优先背景类的检测，而$Iou_c$更关注目标类别的检测，在变化检测中我们更加关注于目标对象的检测，因此$Iou_c$更加重要。从DSIFN-CD数据集的实验结果中可以看到，我们的方法在一些设置下尽管在$OA$上表现不佳，但是在$IoU_c$上取得了最好的结果。而在其余数据集上我们的AdaSemiCD方法总体上都达到了最佳的效果。
\subsection{定性对比}
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.45]{images/Adalevir-vis.png}
  \caption{
    AdaSemiCD与SOTA方法在LEVIR-CD测试集上的变化检测结果可视化对比。
  }
  \label{fig:AdaLevir-vis}
\end{figure}
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.45]{images/Adawhu-vis.png}
  \caption{
    AdaSemiCD与SOTA方法在WHU-CD测试集上的变化检测结果可视化对比。
  }
  \label{fig:AdaWhu-vis}
\end{figure}
为了更清楚地说明我们提出的方法的变化检测性能提升，我们在所有十个不同的数据集的测试集上都进行了可视化，我们展示了部分可视化样例，其中图\ref{fig:AdaWhu-vis}展示了在WHU-CD测试集的部分可视化示例，图\ref{fig:AdaLevir-vis}展示了在WHU-CD测试集的可视化示例，图\ref{fig:AdaCdd-vis}展示了在CDD测试集的可视化示例。很明显，在这些可视化结果中，我们的方法显著减轻了遗漏检测和错误检测这两种常见问题。
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.45]{images/Adacdd-vis.png}
  \caption{
    AdaSemiCD与SOTA方法在CDD测试集上的变化检测结果可视化对比。
  }
  \label{fig:AdaCdd-vis}
  \end{figure}
在具有挑战性的场景下，我们的方法仍然可以有效地识别我们感兴趣的变化区域。例如图\ref{fig:AdaWhu-vis}下半部分的图像对，图像之间存在明显的干扰，由于缺乏足够的标记信息，使得减轻这种干扰具有挑战性，从而导致模型性能下降，许多半监督变化检测方法检测到了建筑物之外的干扰变化。此外，当检测小而密集变化的区域时，任务进一步复杂化，这对模型来说是非常困难的。
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.45]{images/AdaCl-vis.png}
  \caption{
    AdaSemiCD与SOTA方法在CL-CD测试集上的变化检测结果可视化对比。
  }
  \label{fig:AdaCl-vis}
  \end{figure}

在这些复杂的场景中，半监督模型由于错误噪声引导的问题可能导致生成错误的伪标签，当无标记的训练样本占大多数时，这种错误就成为了主流。因此，可以从可视图看出，在这种情况下，半监督变化检测的性能甚至可能比仅在标记数据上监督训练的极限方法表现还要差。另一方面，我们的模型在训练阶段自适应地排除了这些噪声，并在训练过程中自适应地集成更优模型的参数。在这些复杂的情况下，伪标签的质量更高，达到了基本可靠的水平，为模型训练提供了准确的指导信号。很明显我们的模型在这些复杂区域，如图\ref{fig:AdaLevir-vis}、\ref{fig:AdaWhu-vis}、\ref{fig:AdaCdd-vis}以及\ref{fig:AdaCl-vis}中用方框突出显示的区域表现更加出色，这也正是我们所提出的方法要解决的问题。
\subsection{消融实验}
在本小节中，我们进行了消融研究，主要是为了验证每个模块在我们提出的方法中的作用，并探索我们在实验中的一些超参数选择。

\subsubsection{自适应机制有效性}
由于对比的半监督方法与本文模型结构的差异，我们一开始并没有急于验证我们所提出的自适应机制的优越性。相反，我们首先使用经典的平均教师框架作为基线进行了实验，除了为其设置的固定超参数来控制无监督损失的权重外，其余的数据增强和变化检测网络与所有方法保持相同。与单模型和共享权值的双分支网络相比，平均教师框架的优势非常明显。这也证明了扰动一致性和移动指数平均的有效性，在此基础上我们探讨了所提出的自适应机制的效力，此实验在LEVIR-CD数据集上进行。
\begin{table*}[ht]
  % \renewcommand\arraystretch{1.2}
\centering
% \tiny
\caption{AdaSemiCD在LEVIR-CD数据集上的消融研究。}
   \resizebox{0.9\textwidth}{!}{
   % \setlength{\tabcolsep}{9pt}
\begin{tabular}{p{30mm}p{20mm}p{20mm}cp{20mm}p{20mm}cp{20mm}p{20mm}cp{20mm}p{20mm}} %
  \toprule
  \multirow{2}{*}{\parbox[c]{.2\linewidth}{Method}} & \multicolumn{2}{c}{5\%} & & \multicolumn{2}{c}{10\%} & & \multicolumn{2}{c}{20\%} & & \multicolumn{2}{c}{40\%}\\
  \cmidrule{2-3} \cmidrule{5-6} \cmidrule{8-9} \cmidrule{11-12}
  & {$IoU^c$} & {OA} && {$IoU^c$} & {OA} & & {$IoU^c$} & {OA} &&{$IoU^c$} & {OA}\\
  \midrule
  Sup. only   &   61.0 & 97.60 && %5
                  66.8 & 98.13 && %10
                  72.3 & 98.44 && %20
                  74.9 & 98.60 \\ %40
    MT-EMA      &   67.1 {\color{red} (+6.1)} & 98.14 {\color{red}(+0.54)} &&
                  75.0 {\color{red} (+8.2)} & 98.63 {\color{red} (+0.50)} &&
                  76.6 {\color{red} (+4.3)} & 98.71 {\color{red} (+0.27)}&&
                  77.0 {\color{red} (+2.1)} & 98.73 {\color{red} (+0.13)} \\
      MT-AEMA     &   68.9 {\color{red} (+7.9)}& 98.23 {\color{red} (+0.63)} &&
                  76.1 {\color{red} (+9.3)} & 98.66 {\color{red} (+0.53)} &&
                      77.7 {\color{red} (+5.4)} & 98.78 {\color{red} (+0.34)} &&
                  77.8 {\color{red} (+2.9)} & 98.78 {\color{red} (+0.18)} \\
      (MT-EMA)+AF* &  72.0 {\color{red} (+11.0)} & 98.43 {\color{red} (+0.83)} && %5
                  76.8 {\color{red} (+10.0)} & 98.72 {\color{red} (+0.59)} && %10
                77.5 {\color{red} (+5.2)} & 98.74 {\color{red} (+0.30)} && %20
                  78.5 {\color{red} (+3.6)} & 98.80 {\color{red} (+0.20)} \\ %40
  (MT-EMA)+AF &   77.0 {\color{red} (+16.0)} & 98.72 {\color{red} (+1.12)} && %5
                  78.8 {\color{red} (+12.0)} & 98.83 {\color{red} (+0.70)} && %10
                80.4 {\color{red} (+8.1)} & 98.91 {\color{red} (+0.47)} && %20
                  80.0 {\color{red} (+5.1)} & 98.90 {\color{red} (+0.30)} \\ %40
      AdaSemiCD   &   77.7 {\color{red} (+16.7)} & 98.78 {\color{red} (+1.18)} &&
                  79.4 {\color{red} (+12.6)} & 98.87 {\color{red} (+0.74)} &&
                  80.3 {\color{red} (+8.0)} & 98.92 {\color{red} (+0.48)} &&
                  80.6 {\color{red} (+5.7)} & 98.93 {\color{red} (+0.33)} \\
  \bottomrule
\end{tabular}
  }
% \normalsize
\label{tab:AdaModule_ablation}
\end{table*}

我们将所提出的AdaEMA模块和AdaFusion模块分别添加到平均教师框架中，在$Iou_c$上分别取得了1.2和5.1个百分点的平均改进，如表\ref{tab:AdaModule_ablation}所示。表中的*表示，在AdaFusion中，采用自适应机制判断是否进行融合，而在选择融合区域时采用随机选择策略。这与AdaFusion自适应融合之间在性能上存在明显的差距。最后，完整的方法在任意单个模块的性能上去的了进一步的提升，这表明我们提出的两个模块是解耦的，模型体系结构是合理的。

\subsubsection{超参数选择}
无监督损失权重的预热过程对AdaSemiCD在半监督变化检测上的性能有重大影响。因此，我们对控制预热过程的两个超参数（$\gamma$ 和 $w_{max}$） 的选择进行了消融实验。如表\ref{tab:AdaPram_ablation}所示，在参数（0.1，10）、（0.1，0.1）和（0.1，1.0）的组合下，我们的方法在LEVIR-CD、WHU-CD、CDD三个数据集上的性能最佳。而且，我们的方法对该超参数敏感，参数选择不当会造成较大的性能差异。这是因为我们的方法同时对标记样本进行监督训练和对未标记样本进行无监督训练。如果不能很好地平衡两者之间的关系，就会导致标记样本的过拟合或未标记样本的过多噪声干扰。我们剩下的所有实验都是在这个超参数设置下进行的，比较方法的超参数与原论文中的最佳设置一致。但总的来说，通过经验积累发现，$\gamma$我们总是设置为0.1，$w_{max}$可以在{0.1，1.0，10.0，30.0}中进行尝试，由于深度学习的黑盒性，单阶段半监督学习中监督和无监督的互相影响因素较多，我们暂时无法得出一组在所有情况下都适用的最优参数。在其余数据集上我们仅进行了轻微的超参调整就取得了可观的实验结果，我们将$w_{max}$分别设置为：LEVIR-CD+：10.0；GZ-CD：5.0；EGY-CD：5.0；HRCUS-CD：1.0；DSIFN-CD：10.0；SYSU-CD：1.0；CL-CD：1.0。

\begin{table*}[tb]
    % \renewcommand\arraystretch{1.2}
	\centering
	% \tiny
	\caption{超参数敏感性消融实验结果。}
     \resizebox{0.9\textwidth}{!}{
     % \setlength{\tabcolsep}{9pt}
	\begin{tabular}{p{10mm}p{20mm}p{10mm}cp{15mm}p{10mm}cp{15mm}p{10mm}cp{15mm}p{10mm}} %
		\toprule
		\multirow{2}{*}{\parbox[c]{.1\linewidth}{$\gamma$}} & \multirow{2}{*}{$w_{max}$} & \multicolumn{2}{c}{LEVIR-CD} & & \multicolumn{2}{c}{WHU-CD} & & \multicolumn{2}{c}{CDD}\\
	  \cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10}
		&& {$IoU^c$} & {OA} && {$IoU^c$} & {OA} & & {$IoU^c$} & {OA} \\
		\midrule
  	0  & 0 (Sup.Only) &   66.8 & 98.13 && %LEVIR-CD
		                55.7 & 97.53 && %WHU-CD
		                67.9 & 95.46 \\  %CDD
		0.05  & 1.0 &   67.2 & 98.17 && %5
		                53.8 & 97.02 && %WHU-CD
		                74.4 & 96.35 \\  %CDD
	    0.1   & 1.0   &   71.8 & 98.32 && %LEVIR-CD
		                61.0 & 98.10 && %WHU-CD
		                \underline{\textbf{77.3}} & \underline{\textbf{96.89}} \\  %CDD
        0.3   & 1.0   &   69.9 & 98.26 && %LEVIR-CD
		                59.4 & 98.03 && %WHU-CD
		                76.2 & 96.56 \\  %CDD
        0.5   & 1.0   &  68.7 & 98.15 && %LEVIR-CD
		              60.9 & 98.25 && %WHU-CD
		                76.3 & 96.58 \\  %CDD
		1.0   & 1.0   &   67.3 & 98.13 && %LEVIR-CD
		                60.5 & 98.18 && %10
		                72.3 & 95.98 \\ %40
        0.1   & 0.1   &   65.2 & 97.60 && %LEVIR-CD
		                \underline{\textbf{70.8}} & \underline{\textbf{98.70}} && %WHU-CD
		                71.6 & 95.77 \\  %CDD
        0.1   & 0.5   &   68.3 & 98.14 && %LEVIR-CD
		                66.9 & 98.54 && %WHU-CD
		                75.8 & 96.67 \\  %CDD
        0.1   & 5.0   &   73.9 & 98.75 && %LEVIR-CD
		                60.1 & 98.00 && %WHU-CD
		                69.1 & 95.51 \\  %CDD
        0.1   & 10.0   & \underline{\textbf{79.4}} & \underline{\textbf{98.87}} && %LEVIR-CD
		                52.4 & 97.40 && %WHU-CD
		                68.2 & 95.50 \\  %CDD
        0.1   & 30.0   &   71.9 & 98.42 && %LEVIR-CD
		                50.34 & 97.12 && %WHU-CD
		                65.4 & 95.20 \\  %CDD0
		\bottomrule
	\end{tabular}
    }
	% \normalsize
	\label{tab:AdaPram_ablation}
\end{table*}
\subsubsection{计算资源}
虽然引入了额外的自适应机制有效地提高了检测性能，但是一个不可避免的问题就是增加了额外的计算资源消耗，如果耗费了大量的资源而仅仅带来了有限的提升，则得不偿失，因此我们进行了计算资源耗费的实验验证。

实验结果如表\ref{tab:Ada_compute}所示，由于我们对所有实验方法都公平地采用了相同的变化检测网络，因此训练参数数量（46.85M）和计算量（585.85 GFLOPs）都保持相同，我们的AdaSemiCD推理时间方面与其他方法相当。训练时间较长的主要原因是每次训练迭代过程中需要生成和评估两次伪标签，经过统计这一步大约需要0.3s左右，而融合和EMA参数更新分别只需要0.006s和0.03s左右。我们的模型仅仅是前期训练时间增加了25$\%$，但是取得了显著的性能优势，很好地平衡了性能和计算耗费，这对其实际应用具有重要的意义。
\begin{table}[ht]
  \centering
  % \renewcommand\arraystretch{1.2}
  \tiny
  % \caption{Comparison of parameters, computing complexity, training time and inference time of different SSCD methods.}
  \caption{LEVIR-CD数据集上不同方法的参数、计算复杂度和训练时间的比较。}
  % 表格标题
  \label{tab:Ada_compute} % 表格标签，用于引用
   \resizebox{0.9\textwidth}{!}{
  \begin{tabular}{p{20mm}p{15mm}p{15mm}p{25mm}p{30mm}p{10mm}} %
  \toprule % 上边框线
  Method & Params(M) & FLOPs(G) & Training Time(s) &Inference Time(ms) &$IoU^c$\\
  \midrule % 中间分割线
  Sup.Only & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}77 & \hspace{1.3cm}56 & 61.0\\
  AdvEnt\cite{vu2019advent} & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}405 & \hspace{1.3cm}63 & 66.1\\
  s4GAN\cite{mittal2019semi} & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}585 & \hspace{1.3cm}58 & 64.0\\
  SemiCDNet\cite{peng2021SemiCDNet} & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}408 & \hspace{1.3cm}75 & 67.6\\
  RCR\cite{bandara2022RCR} & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}742 & \hspace{1.3cm}59 & 72.5\\
  FPA\cite{Zhang2023FPA} & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}727 & \hspace{1.3cm}68 & 73.7\\
  AdaSemiCD & \hspace{0.3cm}46.85 & \hspace{0.20cm}585.85 & \hspace{1.0cm}915 & \hspace{1.3cm}67 &   \textbf{77.7}\\
  \hline
  Oracle & \hspace{0.3cm}46.85 &
  \hspace{0.20cm}585.85 & \hspace{1.0cm}293 & \hspace{1.3cm}55 & 77.9 \\
  \bottomrule % 下边框线
\end{tabular}
}
\end{table}
\section{本章小结}
本章提出了基于伪标签评估的自适应半监督变化检测算法，首先介绍了基于平均教师模型的整体半监督变化检测框架，包括监督训练、基于一致性正则化的无监督训练两个部分，介绍了总体的损失函数。具体来说，我们对教师模型对未标记训练样本生成的伪标签质量进行评估，并根据评估结果对样本进行自适应的融合，提出了AdaFusion模块，以及对模型参数更新进行自适应的选择，提出了AdaEMA模块，最终提出了AdaSemiCD自适应半监督框架。随后我们介绍了统一的实验设置，与其他几种方法进行了对比实验，从定量和定性两个维度证明了AdaSemiCD的先进性，并设计消融实验验证了各个自适应模块的有效性以及我们的方法中超参数的最优选择。最后从性能和计算开销方面进行了实验探究，我们的方法仅增加了微弱的训练时间开销，而取得了性能上的巨大提升，证明我们的方法是具有实际应用意义的。


\chapter{基于APE的单模型半监督变化检测算法}
\section{引言}
\section{基于APE的单模型半监督变化检测框架}
\subsection{整体框架}
\subsection{基于查询的自动伪标签生成}
\section{实验结果及分析}
\subsection{实验设置}
\subsection{对比试验}
\subsection{消融实验}
\section{本章小结}

\chapter{总结与展望}
\section{本文工作总结}
\section{未来研究展望}

\cleardoublepage
%%=============================================================================%
%% 参考文献以及附录
%%-----------------------------------------------------------------------------%
%% \bibliographystyle{nputhesis}                               % GB/T 7714-2015 格式
\bibliographystyle{nputhesis-noslash}                       % 参考文献改进格式
\bibliography{reference}                                    % 参考文献
\appendix

%%=============================================================================%
%% 文档附页部分（致谢、参加科研情况、知识产权与原创性声明）
%%-----------------------------------------------------------------------------%
\backmatter                                                 % 文档附页部分
%%-----------------------------------------------------------------------------%
\begin{acknowledgements}                                    % 致谢开始
感谢我的老师和我的朋友们……
\end{acknowledgements}                                      % 致谢结束
%%-----------------------------------------------------------------------------%
\begin{accomplishments}                                     % 参加科研情况开始
    [1] ...
\end{accomplishments}                                       % 参加科研情况结束
%%-----------------------------------------------------------------------------%
\makestatement                                              % 知识产权与原创性声明
%%=============================================================================%
%% 文档结束
%%-----------------------------------------------------------------------------%
\end{document}
%%=============================================================================%


%%
%% This work consists of the file  yanputhesis.dtx
%% and the derived files           yanputhesis.ins,
%%                                 yanputhesis.pdf,
%%                                 yanputhesis.cls.
%%
%%
%% End of file `yanputhesis-sample.tex'.
